{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATACHALLENGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour ce datachallenge, nous aurons besoin des modules Python ci-dessous, il vous faut donc évidemment exécuter cette première cellule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les différentes méthodes dont nous aurons besoins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Pour importer les fichiers csv\n",
    "pd.read_csv\n",
    "\n",
    "### Pour créer nos echantillons de train et de test\n",
    "from sklearn import model_selection.train_test_split\n",
    "\n",
    "model_selection.train_test_split\n",
    "\n",
    "### Trouver la meilleur valeur d'un paramètre\n",
    "form sklearn import model_selection\n",
    "\n",
    "model_selection.GridSearchCV\n",
    "\n",
    "### Créer une répartition d'échantillon de test aléatoire\n",
    "from sklearn import model_selection\n",
    "\n",
    "model_selection.KFold\n",
    "\n",
    "### Pour calculer une regression linéaire\n",
    "from sklearn import linear_model\n",
    "\n",
    "linear_model.LogisticRegression\n",
    "\n",
    "### Pour faire une PCA\n",
    "from sklearn import decomposition\n",
    "\n",
    "decomposition.PCA\n",
    "\n",
    "### Classificatuer gaussien\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "### Classificateur k-voisins\n",
    "from sklearn import neighbors\n",
    "\n",
    "neighbors.KNeighborsClassifier\n",
    "\n",
    "### Regression logistique\n",
    "from sklearn import linear_model\n",
    "\n",
    "linear_model.LogisticRegression\n",
    "\n",
    "### Regression logistique lasso\n",
    "from sklearn import linear_model\n",
    "\n",
    "linear_model.LogisticRegressionCV\n",
    "\n",
    "### Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "### Decision Tree Regressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "### Bagged Tree\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "### Random forest regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "### Reseaux de neurones\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons importer toutes les données qui vont nous être utiles, même celles qui ne seront pas utiles avant la fin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "XTrain_Path = \"Xtrain_hgcGIrA.csv\"\n",
    "YTrain_Path = \"Ytrain_yL5OjS4.csv\"\n",
    "XTest_Path = \"Xtest.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "XTrain  =    pd.read_csv(XTrain_Path)\n",
    "YTrain  =    pd.read_csv(YTrain_Path)[\"p0q0\"]\n",
    "XTest  =    pd.read_csv(XTest_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>train</th>\n",
       "      <th>way</th>\n",
       "      <th>station</th>\n",
       "      <th>hour</th>\n",
       "      <th>composition</th>\n",
       "      <th>p1q0</th>\n",
       "      <th>p2q0</th>\n",
       "      <th>p3q0</th>\n",
       "      <th>p0q1</th>\n",
       "      <th>p0q2</th>\n",
       "      <th>p0q3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AD</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AD</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AD</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AD</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AD</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  train  way station      hour  composition  p1q0  p2q0  p3q0  \\\n",
       "0  2019-01-07      1    0      AD  06:00:00            2   NaN   NaN   NaN   \n",
       "1  2019-01-08      1    0      AD  06:00:00            2   NaN   NaN   NaN   \n",
       "2  2019-01-10      1    0      AD  06:00:00            2   NaN   NaN   NaN   \n",
       "3  2019-01-11      1    0      AD  06:00:00            2   NaN   NaN   NaN   \n",
       "4  2019-01-14      1    0      AD  06:00:00            2   NaN   NaN   NaN   \n",
       "\n",
       "    p0q1   p0q2   p0q3  \n",
       "0  0.201  0.138  0.091  \n",
       "1  0.204  0.152  0.106  \n",
       "2  0.213  0.153  0.111  \n",
       "3  0.213  0.152  0.108  \n",
       "4  0.210  0.147  0.096  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTrain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exemple de Découpage train / test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En apprentissage statistique, classiquement un prédicteur est ajusté sur une partie seulement des données et l'erreur de ce dernier est ensuite évaluée sur une autre partie des données disponibles. Ceci permet de ne pas utiliser les mêmes données pour ajuster et évaluer la qualité d'un prédicteur. Cette problématique est l'objet du prochain chapitre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> En utilisant la fonction [`train_test_split`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split) de la librairie [`sklearn.model_selection`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection), on sélectionne aléatoirement 60% des observations pour l'échantillon d'apprentissage et on garde le reste pour l'échantillon de test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "XTrain_train,XTrain_test,YTrain_train, YTrain_test = model_selection.train_test_split(XTrain.to_numpy(), YTrain.to_numpy(), test_size=0.4, train_size=0.6, random_state=0, shuffle=True, stratify=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exemple de transformation des predictions en CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut que l'on obtienne un fichier csv pour tester nos résultats, voici comment on procède"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.216 0.216 0.227 ... 0.139 0.117 0.416]\n"
     ]
    }
   ],
   "source": [
    "prediction = YTrain.to_numpy()\n",
    "print(prediction)\n",
    "\n",
    "df = pd.DataFrame(prediction, columns=['p0q0'])\n",
    "df.to_csv(\"predictionExemple.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Decision tree regressor avec pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Selections des colonnes\n",
    "XTrain_ = XTrain[[\"p0q1\",\"p0q2\", \"p0q3\", \"p1q0\",\"p2q0\",\"p3q0\"]]\n",
    "\n",
    "#Nan -> 0\n",
    "XTrain_ = XTrain_.fillna(0)\n",
    "\n",
    "#Découpage train/test\n",
    "from sklearn import model_selection\n",
    "XTrain_train,XTrain_test,YTrain_train, YTrain_test = model_selection.train_test_split(XTrain_.to_numpy(), YTrain.to_numpy(), test_size=0.4, train_size=0.6, random_state=0, shuffle=True, stratify=None)\n",
    "\n",
    "\n",
    "#Decision Tree Regressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "DTR=DecisionTreeRegressor().fit(XTrain_.to_numpy(), YTrain.to_numpy())\n",
    "prediction = DTR.predict(XTest_.to_numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rendu première méthode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#selection des colonnes\n",
    "XTrain_ = XTrain[[\"p0q1\",\"p0q2\", \"p0q3\", \"p1q0\",\"p2q0\",\"p3q0\"]]\n",
    "XTrain_ = XTrain_.fillna(0)\n",
    "XTest_ = XTest[[\"p0q1\",\"p0q2\", \"p0q3\", \"p1q0\",\"p2q0\",\"p3q0\"]]\n",
    "XTest_ = XTrain_.fillna(0)\n",
    "\n",
    "#Decision Tree Regressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "DTR=DecisionTreeRegressor().fit(XTrain_.to_numpy(), YTrain.to_numpy())\n",
    "prediction = DTR.predict(XTest_.to_numpy())\n",
    "\n",
    "\n",
    "df = pd.DataFrame(prediction, columns=['p0q0'], index = np.arange(1, prediction.size+1))\n",
    "df.to_csv(\"prediction1.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Decision tree regressor avec pq + sens, train, heure, jour, composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#transformation en float des colonnes date et hour\n",
    "from datetime import datetime\n",
    "XTrain_hd = XTrain[[\"hour\",\"date\", \"way\", \"train\", \"composition\"]]\n",
    "XTrain_hd = XTrain_hd.fillna(method='ffill')\n",
    "hour_f = np.zeros((XTrain_hd.shape[0]))\n",
    "day_f = np.zeros((XTrain_hd.shape[0]))\n",
    "\n",
    "for i in range(XTrain_hd.shape[0]):\n",
    "    hour_f[i] = (datetime.strptime(XTrain_hd[\"hour\"][i],'%H:%M:%S')-datetime.strptime('00:00:00','%H:%M:%S')).seconds\n",
    "    day_f[i] = datetime.strptime(XTrain_hd[\"date\"][i],\"%Y-%m-%d\").weekday()\n",
    "    \n",
    "#récupération des colonnes\n",
    "XTrain_ = XTrain[[\"p1q0\",\"p2q0\",\"p3q0\",\"p0q1\",\"p0q2\",\"p0q3\"]]\n",
    "XTrain_ = XTrain_.fillna(XTrain_.mean())\n",
    "\n",
    "XTrain_[\"hour\"]=hour_f\n",
    "XTrain_[\"day\"]=day_f\n",
    "XTrain_[\"way\"]=XTrain_hd[\"way\"]\n",
    "XTrain_[\"train\"]=XTrain_hd[\"train\"]\n",
    "XTrain_[\"composition\"]=XTrain_hd[\"composition\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#même opération pour XTest\n",
    "\n",
    "XTest_hd = XTest[[\"hour\",\"date\", \"way\", \"train\", \"composition\"]]\n",
    "XTest_hd = XTest_hd.fillna(method='ffill')\n",
    "hour_f = np.zeros((XTest_hd.shape[0]))\n",
    "day_f = np.zeros((XTest_hd.shape[0]))\n",
    "\n",
    "for i in range(XTest_hd.shape[0]):\n",
    "    hour_f[i] = (datetime.strptime(XTest_hd[\"hour\"][i],'%H:%M:%S')-datetime.strptime('00:00:00','%H:%M:%S')).seconds\n",
    "    day_f[i] = datetime.strptime(XTest_hd[\"date\"][i],\"%Y-%m-%d\").weekday()\n",
    "    \n",
    "#récupération des colonnes\n",
    "XTest_ = XTest[[\"p1q0\",\"p2q0\",\"p3q0\",\"p0q1\",\"p0q2\",\"p0q3\"]]\n",
    "XTest_ = XTest_.fillna(0)\n",
    "\n",
    "XTest_[\"hour\"]=hour_f\n",
    "XTest_[\"day\"]=day_f\n",
    "XTest_[\"way\"]=XTest_hd[\"way\"]\n",
    "XTest_[\"train\"]=XTest_hd[\"train\"]\n",
    "XTest_[\"composition\"]=XTest_hd[\"composition\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Calcul de modèle de décision tree regressor\n",
    "#FAIRE DES TEST EN CHANGEANT LE CALCUL DE SCORE\n",
    "#Decision Tree Regressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "DTR=DecisionTreeRegressor().fit(XTrain_.to_numpy(), YTrain.to_numpy())\n",
    "prediction = DTR.predict(XTest_.to_numpy())\n",
    "\n",
    "\n",
    "df = pd.DataFrame(prediction, columns=['p0q0'], index = np.arange(1, prediction.size+1))\n",
    "df.to_csv(\"prediction2.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagged Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([ 0.52042961,  5.52087708, 10.43095031, 15.73000121, 20.91146379,\n",
      "       27.25621433, 32.06793742, 35.6737422 , 34.99069366]), 'std_fit_time': array([0.06144129, 0.36334296, 0.36005403, 0.51026154, 0.62106897,\n",
      "       1.14457825, 0.8667517 , 1.00410535, 2.11203338]), 'mean_score_time': array([0.00938063, 0.0254086 , 0.04323816, 0.05611434, 0.07573447,\n",
      "       0.09616084, 0.10656362, 0.11298923, 0.09728808]), 'std_score_time': array([0.00765925, 0.00801315, 0.0060713 , 0.00783067, 0.00560849,\n",
      "       0.00306039, 0.00620546, 0.01835284, 0.01169838]), 'param_n_estimators': masked_array(data=[1, 11, 21, 31, 41, 51, 61, 71, 81],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'n_estimators': 1}, {'n_estimators': 11}, {'n_estimators': 21}, {'n_estimators': 31}, {'n_estimators': 41}, {'n_estimators': 51}, {'n_estimators': 61}, {'n_estimators': 71}, {'n_estimators': 81}], 'split0_test_score': array([0.85543886, 0.93517686, 0.94215407, 0.9427631 , 0.94448174,\n",
      "       0.94256437, 0.94403814, 0.94367639, 0.94393005]), 'split1_test_score': array([0.8472235 , 0.92531231, 0.91713473, 0.92538867, 0.92494368,\n",
      "       0.92205619, 0.92154579, 0.92371945, 0.92451829]), 'split2_test_score': array([0.58304817, 0.60829462, 0.59601207, 0.59816159, 0.60186935,\n",
      "       0.60132295, 0.60210463, 0.5955427 , 0.61133235]), 'split3_test_score': array([0.91636823, 0.95000582, 0.95409713, 0.95538922, 0.95318184,\n",
      "       0.9532679 , 0.95312827, 0.95551804, 0.9548718 ]), 'split4_test_score': array([0.89021385, 0.91861584, 0.92472558, 0.92249107, 0.91863859,\n",
      "       0.92282739, 0.92267231, 0.92539105, 0.92429105]), 'mean_test_score': array([0.81845852, 0.86748109, 0.86682471, 0.86883873, 0.86862304,\n",
      "       0.86840776, 0.86869783, 0.86876953, 0.87178871]), 'std_test_score': array([0.12028977, 0.13002299, 0.13602506, 0.13586639, 0.13396703,\n",
      "       0.13407042, 0.13385271, 0.13712384, 0.13075289]), 'rank_test_score': array([9, 7, 8, 2, 5, 6, 4, 3, 1])}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x28391fe1050>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "n_estimators = np.arange(1,82,10)\n",
    "\n",
    "tuned_parameters = {'n_estimators':n_estimators}\n",
    "\n",
    "Cart_grid = GridSearchCV(\n",
    "    BaggingRegressor(estimator = DecisionTreeRegressor(criterion = \"friedman_mse\")),\n",
    "    tuned_parameters,\n",
    "    n_jobs=-1\n",
    "    )\n",
    "\n",
    "Cart_grid.fit(XTrain_.to_numpy(), YTrain.to_numpy())\n",
    "\n",
    "print(Cart_grid.cv_results_)\n",
    "mean_score = Cart_grid.cv_results_['mean_test_score']\n",
    "import matplotlib.pyplot as plt \n",
    "plt.plot(n_estimators, mean_score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "bagTree = BaggingRegressor(estimator = DecisionTreeRegressor(criterion = \"friedman_mse\"), n_estimators=10)\n",
    "bagTree.fit(XTrain_.to_numpy(), YTrain.to_numpy())\n",
    "\n",
    "prediction = bagTree.predict(XTest_.to_numpy())\n",
    "\n",
    "\n",
    "df = pd.DataFrame(prediction, columns=['p0q0'], index = np.arange(1, prediction.size+1))\n",
    "df.to_csv(\"prediction_bgf10.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.0034744957205418234\n",
      "R-squared: 0.8597012016847498\n",
      "Mean Squared Error: 0.0014263354759007922\n",
      "R-squared: 0.9424051231146472\n"
     ]
    }
   ],
   "source": [
    "# Linear regression - Test\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "XTrain_lr = XTrain[[\"p0q1\",\"p0q2\", \"p0q3\", \"p1q0\",\"p2q0\",\"p3q0\"]]\n",
    "XTrain_lr = XTrain_.fillna(0)\n",
    "\n",
    "XTrain_train,XTrain_test,YTrain_train, YTrain_test = train_test_split(XTrain_lr.to_numpy(), YTrain.to_numpy(), test_size=0.4, train_size=0.6, random_state=0, shuffle=True, stratify=None)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(XTrain_train, YTrain_train)\n",
    "y_pred = model.predict(XTrain_test)\n",
    "mse = mean_squared_error(YTrain_test, y_pred)\n",
    "r2 = r2_score(YTrain_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r2}')\n",
    "\n",
    "# Create a pipeline with polynomial features and Ridge Regression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model = make_pipeline(PolynomialFeatures(4), Ridge(alpha=0))  # Ridge with regularization strength alpha\n",
    "\n",
    "# Train the model\n",
    "model.fit(XTrain_train, YTrain_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(XTrain_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(YTrain_test, y_pred)\n",
    "r2 = r2_score(YTrain_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r2}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Test degrée\n",
    "mse_k = np.zeros(5)\n",
    "r2_k = np.zeros(5)\n",
    "\n",
    "for k in range(2,7):\n",
    "    model = make_pipeline(PolynomialFeatures(k), Ridge(alpha=0)) \n",
    "\n",
    "# Train the model\n",
    "    model.fit(XTrain_train, YTrain_train)\n",
    "\n",
    "# Make predictions\n",
    "    y_pred = model.predict(XTrain_test)\n",
    "\n",
    "# Evaluate the model\n",
    "    mse_k[k-2] = mean_squared_error(YTrain_test, y_pred)\n",
    "    r2_k[k-2] = r2_score(YTrain_test, y_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Test alpha\n",
    "mse_k = np.zeros(20)\n",
    "r2_k = np.zeros(20)\n",
    "\n",
    "for k in range(20):\n",
    "    model = make_pipeline(PolynomialFeatures(4), Ridge(alpha=k*0.001)) \n",
    "\n",
    "# Train the model\n",
    "    model.fit(XTrain_train, YTrain_train)\n",
    "\n",
    "# Make predictions\n",
    "    y_pred = model.predict(XTrain_test)\n",
    "\n",
    "# Evaluate the model\n",
    "    mse_k[k] = mean_squared_error(YTrain_test, y_pred)\n",
    "    r2_k[k] = r2_score(YTrain_test, y_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b945908d10>]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.plot(mse_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b945948ad0>]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.plot(r2_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Linear regression - Real Prediction\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "XTrain_lr = XTrain[[\"p0q1\",\"p0q2\", \"p0q3\", \"p1q0\",\"p2q0\",\"p3q0\"]]\n",
    "XTrain_lr = XTrain_.fillna(0)\n",
    "XTest_ = XTest[[\"p0q1\",\"p0q2\", \"p0q3\", \"p1q0\",\"p2q0\",\"p3q0\"]]\n",
    "XTest_ = XTest_.fillna(0)\n",
    "\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(XTrain_lr, YTrain)\n",
    "y_pred = model.predict(XTest_)\n",
    "\n",
    "df = pd.DataFrame(y_pred, columns=['p0q0'], index = np.arange(1, y_pred.size+1))\n",
    "df.to_csv(\"prediction_lr.csv\")\n",
    "\n",
    "# Ridge - Real Prediction\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "XTrain_lr = XTrain[[\"p0q1\",\"p0q2\", \"p0q3\", \"p1q0\",\"p2q0\",\"p3q0\"]]\n",
    "XTrain_lr = XTrain_.fillna(0)\n",
    "XTest_ = XTest[[\"p0q1\",\"p0q2\", \"p0q3\", \"p1q0\",\"p2q0\",\"p3q0\"]]\n",
    "XTest_ = XTest_.fillna(0)\n",
    "\n",
    "\n",
    "model = make_pipeline(PolynomialFeatures(4), Ridge(alpha=0))\n",
    "model.fit(XTrain_lr, YTrain)\n",
    "y_pred = model.predict(XTest_)\n",
    "\n",
    "df = pd.DataFrame(y_pred, columns=['p0q0'], index = np.arange(1, y_pred.size+1))\n",
    "df.to_csv(\"prediction_r.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réseau de Neurone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.3476927e-01 2.5139275e-01 3.1686702e-01 2.0720035e-01 2.2216721e-01\n",
      "  2.0984516e-01 2.6587627e+04 1.9232620e+00 0.0000000e+00 2.7067989e+01\n",
      "  1.9996463e+00]]\n",
      "Epoch 1/10000\n",
      "249/249 [==============================] - 2s 5ms/step - loss: 0.0411 - val_loss: 0.0458\n",
      "Epoch 2/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0218 - val_loss: 0.0411\n",
      "Epoch 3/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0185 - val_loss: 0.0433\n",
      "Epoch 4/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0165 - val_loss: 0.0428\n",
      "Epoch 5/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0158 - val_loss: 0.0418\n",
      "Epoch 6/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0148 - val_loss: 0.0398\n",
      "Epoch 7/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0141 - val_loss: 0.0384\n",
      "Epoch 8/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0136 - val_loss: 0.0382\n",
      "Epoch 9/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0133 - val_loss: 0.0409\n",
      "Epoch 10/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0129 - val_loss: 0.0401\n",
      "Epoch 11/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0125 - val_loss: 0.0419\n",
      "Epoch 12/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0124 - val_loss: 0.0415\n",
      "Epoch 13/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0123 - val_loss: 0.0383\n",
      "Epoch 14/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0121 - val_loss: 0.0395\n",
      "Epoch 15/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0117 - val_loss: 0.0380\n",
      "Epoch 16/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0116 - val_loss: 0.0410\n",
      "Epoch 17/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0116 - val_loss: 0.0414\n",
      "Epoch 18/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0114 - val_loss: 0.0399\n",
      "Epoch 19/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0116 - val_loss: 0.0411\n",
      "Epoch 20/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0113 - val_loss: 0.0401\n",
      "Epoch 21/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0113 - val_loss: 0.0413\n",
      "Epoch 22/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0109 - val_loss: 0.0432\n",
      "Epoch 23/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0108 - val_loss: 0.0403\n",
      "Epoch 24/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0108 - val_loss: 0.0451\n",
      "Epoch 25/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0107 - val_loss: 0.0446\n",
      "Epoch 26/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0106 - val_loss: 0.0444\n",
      "Epoch 27/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0105 - val_loss: 0.0428\n",
      "Epoch 28/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0105 - val_loss: 0.0440\n",
      "Epoch 29/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0105 - val_loss: 0.0446\n",
      "Epoch 30/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0105 - val_loss: 0.0411\n",
      "Epoch 31/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0104 - val_loss: 0.0412\n",
      "Epoch 32/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0102 - val_loss: 0.0426\n",
      "Epoch 33/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0101 - val_loss: 0.0446\n",
      "Epoch 34/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0101 - val_loss: 0.0481\n",
      "Epoch 35/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0100 - val_loss: 0.0420\n",
      "Epoch 36/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0101 - val_loss: 0.0437\n",
      "Epoch 37/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0099 - val_loss: 0.0457\n",
      "Epoch 38/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0100 - val_loss: 0.0454\n",
      "Epoch 39/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0098 - val_loss: 0.0454\n",
      "Epoch 40/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0097 - val_loss: 0.0435\n",
      "Epoch 41/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0097 - val_loss: 0.0438\n",
      "Epoch 42/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0096 - val_loss: 0.0434\n",
      "Epoch 43/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0097 - val_loss: 0.0453\n",
      "Epoch 44/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0095 - val_loss: 0.0503\n",
      "Epoch 45/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0095 - val_loss: 0.0432\n",
      "Epoch 46/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0095 - val_loss: 0.0447\n",
      "Epoch 47/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0095 - val_loss: 0.0435\n",
      "Epoch 48/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0092 - val_loss: 0.0429\n",
      "Epoch 49/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0093 - val_loss: 0.0436\n",
      "Epoch 50/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0093 - val_loss: 0.0435\n",
      "Epoch 51/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0092 - val_loss: 0.0412\n",
      "Epoch 52/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0092 - val_loss: 0.0417\n",
      "Epoch 53/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0092 - val_loss: 0.0439\n",
      "Epoch 54/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0092 - val_loss: 0.0428\n",
      "Epoch 55/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0091 - val_loss: 0.0437\n",
      "Epoch 56/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0090 - val_loss: 0.0437\n",
      "Epoch 57/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0091 - val_loss: 0.0452\n",
      "Epoch 58/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0090 - val_loss: 0.0445\n",
      "Epoch 59/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0090 - val_loss: 0.0449\n",
      "Epoch 60/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0089 - val_loss: 0.0458\n",
      "Epoch 61/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0091 - val_loss: 0.0454\n",
      "Epoch 62/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0091 - val_loss: 0.0437\n",
      "Epoch 63/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0088 - val_loss: 0.0432\n",
      "Epoch 64/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0088 - val_loss: 0.0430\n",
      "Epoch 65/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0089 - val_loss: 0.0434\n",
      "Epoch 66/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0087 - val_loss: 0.0492\n",
      "Epoch 67/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0087 - val_loss: 0.0423\n",
      "Epoch 68/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0088 - val_loss: 0.0416\n",
      "Epoch 69/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0088 - val_loss: 0.0421\n",
      "Epoch 70/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0086 - val_loss: 0.0430\n",
      "Epoch 71/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0087 - val_loss: 0.0448\n",
      "Epoch 72/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0086 - val_loss: 0.0459\n",
      "Epoch 73/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0087 - val_loss: 0.0408\n",
      "Epoch 74/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0085 - val_loss: 0.0417\n",
      "Epoch 75/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0085 - val_loss: 0.0467\n",
      "Epoch 76/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0086 - val_loss: 0.0428\n",
      "Epoch 77/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0085 - val_loss: 0.0434\n",
      "Epoch 78/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0085 - val_loss: 0.0421\n",
      "Epoch 79/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0084 - val_loss: 0.0424\n",
      "Epoch 80/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0084 - val_loss: 0.0428\n",
      "Epoch 81/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0084 - val_loss: 0.0448\n",
      "Epoch 82/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0084 - val_loss: 0.0432\n",
      "Epoch 83/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0083 - val_loss: 0.0424\n",
      "Epoch 84/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0084 - val_loss: 0.0433\n",
      "Epoch 85/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0082 - val_loss: 0.0438\n",
      "Epoch 86/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0082 - val_loss: 0.0433\n",
      "Epoch 87/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0083 - val_loss: 0.0442\n",
      "Epoch 88/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0084 - val_loss: 0.0436\n",
      "Epoch 89/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0081 - val_loss: 0.0490\n",
      "Epoch 90/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0082 - val_loss: 0.0444\n",
      "Epoch 91/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0082 - val_loss: 0.0415\n",
      "Epoch 92/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0082 - val_loss: 0.0455\n",
      "Epoch 93/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0081 - val_loss: 0.0439\n",
      "Epoch 94/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0082 - val_loss: 0.0437\n",
      "Epoch 95/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0081 - val_loss: 0.0435\n",
      "Epoch 96/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0081 - val_loss: 0.0440\n",
      "Epoch 97/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0081 - val_loss: 0.0448\n",
      "Epoch 98/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0079 - val_loss: 0.0446\n",
      "Epoch 99/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0080 - val_loss: 0.0427\n",
      "Epoch 100/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0079 - val_loss: 0.0437\n",
      "Epoch 101/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0079 - val_loss: 0.0415\n",
      "Epoch 102/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0079 - val_loss: 0.0443\n",
      "Epoch 103/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0080 - val_loss: 0.0437\n",
      "Epoch 104/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0079 - val_loss: 0.0405\n",
      "Epoch 105/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0078 - val_loss: 0.0416\n",
      "Epoch 106/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0078 - val_loss: 0.0419\n",
      "Epoch 107/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0078 - val_loss: 0.0436\n",
      "Epoch 108/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0078 - val_loss: 0.0441\n",
      "Epoch 109/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0077 - val_loss: 0.0447\n",
      "Epoch 110/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0077 - val_loss: 0.0432\n",
      "Epoch 111/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0077 - val_loss: 0.0462\n",
      "Epoch 112/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0077 - val_loss: 0.0420\n",
      "Epoch 113/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0077 - val_loss: 0.0419\n",
      "Epoch 114/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0078 - val_loss: 0.0415\n",
      "Epoch 115/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0077 - val_loss: 0.0453\n",
      "Epoch 116/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0077 - val_loss: 0.0449\n",
      "Epoch 117/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0077 - val_loss: 0.0464\n",
      "Epoch 118/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0077 - val_loss: 0.0455\n",
      "Epoch 119/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0076 - val_loss: 0.0476\n",
      "Epoch 120/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0076 - val_loss: 0.0430\n",
      "Epoch 121/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0076 - val_loss: 0.0420\n",
      "Epoch 122/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0075 - val_loss: 0.0426\n",
      "Epoch 123/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0075 - val_loss: 0.0453\n",
      "Epoch 124/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0075 - val_loss: 0.0458\n",
      "Epoch 125/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0075 - val_loss: 0.0444\n",
      "Epoch 126/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0075 - val_loss: 0.0448\n",
      "Epoch 127/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0075 - val_loss: 0.0430\n",
      "Epoch 128/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0075 - val_loss: 0.0451\n",
      "Epoch 129/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0075 - val_loss: 0.0460\n",
      "Epoch 130/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0074 - val_loss: 0.0442\n",
      "Epoch 131/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0074 - val_loss: 0.0426\n",
      "Epoch 132/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0074 - val_loss: 0.0413\n",
      "Epoch 133/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0075 - val_loss: 0.0416\n",
      "Epoch 134/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0074 - val_loss: 0.0423\n",
      "Epoch 135/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0074 - val_loss: 0.0431\n",
      "Epoch 136/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0074 - val_loss: 0.0420\n",
      "Epoch 137/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0074 - val_loss: 0.0417\n",
      "Epoch 138/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0073 - val_loss: 0.0424\n",
      "Epoch 139/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0072 - val_loss: 0.0438\n",
      "Epoch 140/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0072 - val_loss: 0.0434\n",
      "Epoch 141/10000\n",
      "249/249 [==============================] - 2s 9ms/step - loss: 0.0073 - val_loss: 0.0434\n",
      "Epoch 142/10000\n",
      "249/249 [==============================] - 2s 8ms/step - loss: 0.0072 - val_loss: 0.0450\n",
      "Epoch 143/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0072 - val_loss: 0.0436\n",
      "Epoch 144/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0072 - val_loss: 0.0437\n",
      "Epoch 145/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0073 - val_loss: 0.0440\n",
      "Epoch 146/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0072 - val_loss: 0.0448\n",
      "Epoch 147/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0072 - val_loss: 0.0438\n",
      "Epoch 148/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0072 - val_loss: 0.0400\n",
      "Epoch 149/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0071 - val_loss: 0.0449\n",
      "Epoch 150/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0072 - val_loss: 0.0430\n",
      "Epoch 151/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0071 - val_loss: 0.0448\n",
      "Epoch 152/10000\n",
      "249/249 [==============================] - 2s 10ms/step - loss: 0.0071 - val_loss: 0.0437\n",
      "Epoch 153/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0071 - val_loss: 0.0452\n",
      "Epoch 154/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0071 - val_loss: 0.0426\n",
      "Epoch 155/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0071 - val_loss: 0.0434\n",
      "Epoch 156/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0070 - val_loss: 0.0446\n",
      "Epoch 157/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0070 - val_loss: 0.0444\n",
      "Epoch 158/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0072 - val_loss: 0.0451\n",
      "Epoch 159/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0070 - val_loss: 0.0461\n",
      "Epoch 160/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0070 - val_loss: 0.0487\n",
      "Epoch 161/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0072 - val_loss: 0.0472\n",
      "Epoch 162/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0072 - val_loss: 0.0498\n",
      "Epoch 163/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0071 - val_loss: 0.0456\n",
      "Epoch 164/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0070 - val_loss: 0.0448\n",
      "Epoch 165/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0070 - val_loss: 0.0432\n",
      "Epoch 166/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0071 - val_loss: 0.0474\n",
      "Epoch 167/10000\n",
      "249/249 [==============================] - 2s 8ms/step - loss: 0.0070 - val_loss: 0.0466\n",
      "Epoch 168/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0070 - val_loss: 0.0450\n",
      "Epoch 169/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0069 - val_loss: 0.0415\n",
      "Epoch 170/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0071 - val_loss: 0.0450\n",
      "Epoch 171/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0069 - val_loss: 0.0438\n",
      "Epoch 172/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0071 - val_loss: 0.0464\n",
      "Epoch 173/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0069 - val_loss: 0.0444\n",
      "Epoch 174/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0069 - val_loss: 0.0482\n",
      "Epoch 175/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0070 - val_loss: 0.0497\n",
      "Epoch 176/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0069 - val_loss: 0.0454\n",
      "Epoch 177/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0068 - val_loss: 0.0472\n",
      "Epoch 178/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0069 - val_loss: 0.0442\n",
      "Epoch 179/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0069 - val_loss: 0.0445\n",
      "Epoch 180/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0069 - val_loss: 0.0438\n",
      "Epoch 181/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0069 - val_loss: 0.0483\n",
      "Epoch 182/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0068 - val_loss: 0.0446\n",
      "Epoch 183/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0069 - val_loss: 0.0448\n",
      "Epoch 184/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0069 - val_loss: 0.0450\n",
      "Epoch 185/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0068 - val_loss: 0.0446\n",
      "Epoch 186/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0068 - val_loss: 0.0453\n",
      "Epoch 187/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0067 - val_loss: 0.0446\n",
      "Epoch 188/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0068 - val_loss: 0.0469\n",
      "Epoch 189/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0068 - val_loss: 0.0427\n",
      "Epoch 190/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0068 - val_loss: 0.0438\n",
      "Epoch 191/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0068 - val_loss: 0.0436\n",
      "Epoch 192/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0067 - val_loss: 0.0413\n",
      "Epoch 193/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0068 - val_loss: 0.0427\n",
      "Epoch 194/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0067 - val_loss: 0.0418\n",
      "Epoch 195/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0068 - val_loss: 0.0414\n",
      "Epoch 196/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0068 - val_loss: 0.0435\n",
      "Epoch 197/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0068 - val_loss: 0.0437\n",
      "Epoch 198/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0067 - val_loss: 0.0429\n",
      "Epoch 199/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0067 - val_loss: 0.0440\n",
      "Epoch 200/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0068 - val_loss: 0.0423\n",
      "Epoch 201/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0067 - val_loss: 0.0440\n",
      "Epoch 202/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0067 - val_loss: 0.0432\n",
      "Epoch 203/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0066 - val_loss: 0.0415\n",
      "Epoch 204/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0068 - val_loss: 0.0433\n",
      "Epoch 205/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0066 - val_loss: 0.0434\n",
      "Epoch 206/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0067 - val_loss: 0.0445\n",
      "Epoch 207/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0066 - val_loss: 0.0427\n",
      "Epoch 208/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0068 - val_loss: 0.0443\n",
      "Epoch 209/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0066 - val_loss: 0.0460\n",
      "Epoch 210/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0066 - val_loss: 0.0448\n",
      "Epoch 211/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0066 - val_loss: 0.0458\n",
      "Epoch 212/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0066 - val_loss: 0.0446\n",
      "Epoch 213/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0066 - val_loss: 0.0443\n",
      "Epoch 214/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0066 - val_loss: 0.0432\n",
      "Epoch 215/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0066 - val_loss: 0.0425\n",
      "Epoch 216/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0065 - val_loss: 0.0457\n",
      "Epoch 217/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0066 - val_loss: 0.0446\n",
      "Epoch 218/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0065 - val_loss: 0.0473\n",
      "Epoch 219/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0066 - val_loss: 0.0429\n",
      "Epoch 220/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0066 - val_loss: 0.0420\n",
      "Epoch 221/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0065 - val_loss: 0.0439\n",
      "Epoch 222/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0065 - val_loss: 0.0431\n",
      "Epoch 223/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0066 - val_loss: 0.0416\n",
      "Epoch 224/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0064 - val_loss: 0.0433\n",
      "Epoch 225/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0065 - val_loss: 0.0463\n",
      "Epoch 226/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0066 - val_loss: 0.0427\n",
      "Epoch 227/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0064 - val_loss: 0.0452\n",
      "Epoch 228/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0065 - val_loss: 0.0422\n",
      "Epoch 229/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0064 - val_loss: 0.0440\n",
      "Epoch 230/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0065 - val_loss: 0.0431\n",
      "Epoch 231/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0064 - val_loss: 0.0431\n",
      "Epoch 232/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0064 - val_loss: 0.0459\n",
      "Epoch 233/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0065 - val_loss: 0.0429\n",
      "Epoch 234/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0064 - val_loss: 0.0447\n",
      "Epoch 235/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0064 - val_loss: 0.0431\n",
      "Epoch 236/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0064 - val_loss: 0.0430\n",
      "Epoch 237/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0064 - val_loss: 0.0422\n",
      "Epoch 238/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0064 - val_loss: 0.0424\n",
      "Epoch 239/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0063 - val_loss: 0.0433\n",
      "Epoch 240/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0063 - val_loss: 0.0429\n",
      "Epoch 241/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0064 - val_loss: 0.0437\n",
      "Epoch 242/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0064 - val_loss: 0.0457\n",
      "Epoch 243/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0064 - val_loss: 0.0429\n",
      "Epoch 244/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0063 - val_loss: 0.0445\n",
      "Epoch 245/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0063 - val_loss: 0.0430\n",
      "Epoch 246/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0064 - val_loss: 0.0434\n",
      "Epoch 247/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0063 - val_loss: 0.0435\n",
      "Epoch 248/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0062 - val_loss: 0.0428\n",
      "Epoch 249/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0064 - val_loss: 0.0448\n",
      "Epoch 250/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0063 - val_loss: 0.0457\n",
      "Epoch 251/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0064 - val_loss: 0.0423\n",
      "Epoch 252/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0064 - val_loss: 0.0427\n",
      "Epoch 253/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0063 - val_loss: 0.0431\n",
      "Epoch 254/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0063 - val_loss: 0.0465\n",
      "Epoch 255/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0063 - val_loss: 0.0449\n",
      "Epoch 256/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0063 - val_loss: 0.0405\n",
      "Epoch 257/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0062 - val_loss: 0.0432\n",
      "Epoch 258/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0062 - val_loss: 0.0434\n",
      "Epoch 259/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0062 - val_loss: 0.0440\n",
      "Epoch 260/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0062 - val_loss: 0.0441\n",
      "Epoch 261/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0063 - val_loss: 0.0461\n",
      "Epoch 262/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0063 - val_loss: 0.0446\n",
      "Epoch 263/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0062 - val_loss: 0.0455\n",
      "Epoch 264/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0062 - val_loss: 0.0454\n",
      "Epoch 265/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0062 - val_loss: 0.0431\n",
      "Epoch 266/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0062 - val_loss: 0.0516\n",
      "Epoch 267/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0061 - val_loss: 0.0475\n",
      "Epoch 268/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0061 - val_loss: 0.0473\n",
      "Epoch 269/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0062 - val_loss: 0.0454\n",
      "Epoch 270/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0062 - val_loss: 0.0458\n",
      "Epoch 271/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0062 - val_loss: 0.0466\n",
      "Epoch 272/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0062 - val_loss: 0.0472\n",
      "Epoch 273/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0062 - val_loss: 0.0479\n",
      "Epoch 274/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0062 - val_loss: 0.0440\n",
      "Epoch 275/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0062 - val_loss: 0.0446\n",
      "Epoch 276/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0062 - val_loss: 0.0428\n",
      "Epoch 277/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0061 - val_loss: 0.0436\n",
      "Epoch 278/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0061 - val_loss: 0.0458\n",
      "Epoch 279/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0062 - val_loss: 0.0453\n",
      "Epoch 280/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0062 - val_loss: 0.0425\n",
      "Epoch 281/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0061 - val_loss: 0.0444\n",
      "Epoch 282/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0061 - val_loss: 0.0448\n",
      "Epoch 283/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0061 - val_loss: 0.0435\n",
      "Epoch 284/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0061 - val_loss: 0.0437\n",
      "Epoch 285/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0061 - val_loss: 0.0484\n",
      "Epoch 286/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0062 - val_loss: 0.0432\n",
      "Epoch 287/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0062 - val_loss: 0.0453\n",
      "Epoch 288/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0060 - val_loss: 0.0480\n",
      "Epoch 289/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0061 - val_loss: 0.0428\n",
      "Epoch 290/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0060 - val_loss: 0.0424\n",
      "Epoch 291/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0060 - val_loss: 0.0456\n",
      "Epoch 292/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0060 - val_loss: 0.0448\n",
      "Epoch 293/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0061 - val_loss: 0.0418\n",
      "Epoch 294/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0061 - val_loss: 0.0407\n",
      "Epoch 295/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0060 - val_loss: 0.0461\n",
      "Epoch 296/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0061 - val_loss: 0.0440\n",
      "Epoch 297/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0061 - val_loss: 0.0414\n",
      "Epoch 298/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0060 - val_loss: 0.0430\n",
      "Epoch 299/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0061 - val_loss: 0.0407\n",
      "Epoch 300/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0060 - val_loss: 0.0411\n",
      "Epoch 301/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0060 - val_loss: 0.0427\n",
      "Epoch 302/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0061 - val_loss: 0.0429\n",
      "Epoch 303/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0060 - val_loss: 0.0456\n",
      "Epoch 304/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0059 - val_loss: 0.0460\n",
      "Epoch 305/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0059 - val_loss: 0.0445\n",
      "Epoch 306/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0059 - val_loss: 0.0405\n",
      "Epoch 307/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0060 - val_loss: 0.0443\n",
      "Epoch 308/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0060 - val_loss: 0.0429\n",
      "Epoch 309/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0060 - val_loss: 0.0455\n",
      "Epoch 310/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0060 - val_loss: 0.0446\n",
      "Epoch 311/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0060 - val_loss: 0.0432\n",
      "Epoch 312/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0059 - val_loss: 0.0452\n",
      "Epoch 313/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0060 - val_loss: 0.0471\n",
      "Epoch 314/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0060 - val_loss: 0.0424\n",
      "Epoch 315/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0059 - val_loss: 0.0429\n",
      "Epoch 316/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0059 - val_loss: 0.0433\n",
      "Epoch 317/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0060 - val_loss: 0.0416\n",
      "Epoch 318/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0059 - val_loss: 0.0419\n",
      "Epoch 319/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0059 - val_loss: 0.0452\n",
      "Epoch 320/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0059 - val_loss: 0.0440\n",
      "Epoch 321/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0060 - val_loss: 0.0434\n",
      "Epoch 322/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0059 - val_loss: 0.0437\n",
      "Epoch 323/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0059 - val_loss: 0.0456\n",
      "Epoch 324/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0059 - val_loss: 0.0476\n",
      "Epoch 325/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0059 - val_loss: 0.0462\n",
      "Epoch 326/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0059 - val_loss: 0.0459\n",
      "Epoch 327/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0060 - val_loss: 0.0453\n",
      "Epoch 328/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0060 - val_loss: 0.0462\n",
      "Epoch 329/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0058 - val_loss: 0.0479\n",
      "Epoch 330/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0058 - val_loss: 0.0441\n",
      "Epoch 331/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0060 - val_loss: 0.0485\n",
      "Epoch 332/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0058 - val_loss: 0.0457\n",
      "Epoch 333/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0059 - val_loss: 0.0446\n",
      "Epoch 334/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0059 - val_loss: 0.0451\n",
      "Epoch 335/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0058 - val_loss: 0.0486\n",
      "Epoch 336/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0058 - val_loss: 0.0462\n",
      "Epoch 337/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0058 - val_loss: 0.0445\n",
      "Epoch 338/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0058 - val_loss: 0.0446\n",
      "Epoch 339/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0058 - val_loss: 0.0452\n",
      "Epoch 340/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0059 - val_loss: 0.0433\n",
      "Epoch 341/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0058 - val_loss: 0.0459\n",
      "Epoch 342/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0058 - val_loss: 0.0424\n",
      "Epoch 343/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0057 - val_loss: 0.0447\n",
      "Epoch 344/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0058 - val_loss: 0.0460\n",
      "Epoch 345/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0058 - val_loss: 0.0495\n",
      "Epoch 346/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0059 - val_loss: 0.0440\n",
      "Epoch 347/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0059 - val_loss: 0.0441\n",
      "Epoch 348/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0058 - val_loss: 0.0450\n",
      "Epoch 349/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0058 - val_loss: 0.0426\n",
      "Epoch 350/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0058 - val_loss: 0.0438\n",
      "Epoch 351/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0057 - val_loss: 0.0438\n",
      "Epoch 352/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0057 - val_loss: 0.0434\n",
      "Epoch 353/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0057 - val_loss: 0.0431\n",
      "Epoch 354/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0057 - val_loss: 0.0440\n",
      "Epoch 355/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0057 - val_loss: 0.0437\n",
      "Epoch 356/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0057 - val_loss: 0.0457\n",
      "Epoch 357/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0057 - val_loss: 0.0437\n",
      "Epoch 358/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0057 - val_loss: 0.0426\n",
      "Epoch 359/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0057 - val_loss: 0.0450\n",
      "Epoch 360/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0057 - val_loss: 0.0435\n",
      "Epoch 361/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0057 - val_loss: 0.0433\n",
      "Epoch 362/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0058 - val_loss: 0.0441\n",
      "Epoch 363/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0057 - val_loss: 0.0411\n",
      "Epoch 364/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0057 - val_loss: 0.0428\n",
      "Epoch 365/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0058 - val_loss: 0.0427\n",
      "Epoch 366/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0058 - val_loss: 0.0473\n",
      "Epoch 367/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0057 - val_loss: 0.0419\n",
      "Epoch 368/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0057 - val_loss: 0.0437\n",
      "Epoch 369/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0057 - val_loss: 0.0425\n",
      "Epoch 370/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0057 - val_loss: 0.0446\n",
      "Epoch 371/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0058 - val_loss: 0.0405\n",
      "Epoch 372/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0057 - val_loss: 0.0396\n",
      "Epoch 373/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0057 - val_loss: 0.0414\n",
      "Epoch 374/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0058 - val_loss: 0.0406\n",
      "Epoch 375/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0057 - val_loss: 0.0417\n",
      "Epoch 376/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0056 - val_loss: 0.0414\n",
      "Epoch 377/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0057 - val_loss: 0.0437\n",
      "Epoch 378/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0057 - val_loss: 0.0428\n",
      "Epoch 379/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0056 - val_loss: 0.0406\n",
      "Epoch 380/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0057 - val_loss: 0.0418\n",
      "Epoch 381/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0057 - val_loss: 0.0423\n",
      "Epoch 382/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0057 - val_loss: 0.0427\n",
      "Epoch 383/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0056 - val_loss: 0.0397\n",
      "Epoch 384/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0056 - val_loss: 0.0389\n",
      "Epoch 385/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0057 - val_loss: 0.0386\n",
      "Epoch 386/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0057 - val_loss: 0.0423\n",
      "Epoch 387/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0056 - val_loss: 0.0376\n",
      "Epoch 388/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0056 - val_loss: 0.0392\n",
      "Epoch 389/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0057 - val_loss: 0.0384\n",
      "Epoch 390/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0057 - val_loss: 0.0395\n",
      "Epoch 391/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0057 - val_loss: 0.0382\n",
      "Epoch 392/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0057 - val_loss: 0.0387\n",
      "Epoch 393/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0055 - val_loss: 0.0401\n",
      "Epoch 394/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0056 - val_loss: 0.0395\n",
      "Epoch 395/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0056 - val_loss: 0.0383\n",
      "Epoch 396/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0056 - val_loss: 0.0387\n",
      "Epoch 397/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0056 - val_loss: 0.0402\n",
      "Epoch 398/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0055 - val_loss: 0.0399\n",
      "Epoch 399/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0056 - val_loss: 0.0410\n",
      "Epoch 400/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0055 - val_loss: 0.0417\n",
      "Epoch 401/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0055 - val_loss: 0.0399\n",
      "Epoch 402/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0056 - val_loss: 0.0457\n",
      "Epoch 403/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0055 - val_loss: 0.0421\n",
      "Epoch 404/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0056 - val_loss: 0.0392\n",
      "Epoch 405/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0056 - val_loss: 0.0405\n",
      "Epoch 406/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0056 - val_loss: 0.0405\n",
      "Epoch 407/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0056 - val_loss: 0.0387\n",
      "Epoch 408/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0055 - val_loss: 0.0402\n",
      "Epoch 409/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0056 - val_loss: 0.0400\n",
      "Epoch 410/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0055 - val_loss: 0.0380\n",
      "Epoch 411/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0056 - val_loss: 0.0388\n",
      "Epoch 412/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0055 - val_loss: 0.0413\n",
      "Epoch 413/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0056 - val_loss: 0.0418\n",
      "Epoch 414/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0056 - val_loss: 0.0387\n",
      "Epoch 415/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0054 - val_loss: 0.0388\n",
      "Epoch 416/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0055 - val_loss: 0.0402\n",
      "Epoch 417/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0055 - val_loss: 0.0403\n",
      "Epoch 418/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0055 - val_loss: 0.0396\n",
      "Epoch 419/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0056 - val_loss: 0.0410\n",
      "Epoch 420/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0056 - val_loss: 0.0410\n",
      "Epoch 421/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0055 - val_loss: 0.0404\n",
      "Epoch 422/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0055 - val_loss: 0.0423\n",
      "Epoch 423/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0055 - val_loss: 0.0414\n",
      "Epoch 424/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0055 - val_loss: 0.0416\n",
      "Epoch 425/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0055 - val_loss: 0.0434\n",
      "Epoch 426/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0055 - val_loss: 0.0442\n",
      "Epoch 427/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0055 - val_loss: 0.0426\n",
      "Epoch 428/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0054 - val_loss: 0.0417\n",
      "Epoch 429/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0055 - val_loss: 0.0410\n",
      "Epoch 430/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0055 - val_loss: 0.0426\n",
      "Epoch 431/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0055 - val_loss: 0.0407\n",
      "Epoch 432/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0056 - val_loss: 0.0463\n",
      "Epoch 433/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0055 - val_loss: 0.0407\n",
      "Epoch 434/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0056 - val_loss: 0.0394\n",
      "Epoch 435/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0054 - val_loss: 0.0397\n",
      "Epoch 436/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0054 - val_loss: 0.0400\n",
      "Epoch 437/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0054 - val_loss: 0.0377\n",
      "Epoch 438/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0054 - val_loss: 0.0399\n",
      "Epoch 439/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0055 - val_loss: 0.0395\n",
      "Epoch 440/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0054 - val_loss: 0.0380\n",
      "Epoch 441/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0054 - val_loss: 0.0402\n",
      "Epoch 442/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0055 - val_loss: 0.0407\n",
      "Epoch 443/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0054 - val_loss: 0.0411\n",
      "Epoch 444/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0054 - val_loss: 0.0392\n",
      "Epoch 445/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0054 - val_loss: 0.0413\n",
      "Epoch 446/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0054 - val_loss: 0.0411\n",
      "Epoch 447/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0054 - val_loss: 0.0422\n",
      "Epoch 448/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0054 - val_loss: 0.0407\n",
      "Epoch 449/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0054 - val_loss: 0.0413\n",
      "Epoch 450/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0055 - val_loss: 0.0391\n",
      "Epoch 451/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0056 - val_loss: 0.0421\n",
      "Epoch 452/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0055 - val_loss: 0.0410\n",
      "Epoch 453/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0055 - val_loss: 0.0399\n",
      "Epoch 454/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0054 - val_loss: 0.0397\n",
      "Epoch 455/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0054 - val_loss: 0.0414\n",
      "Epoch 456/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0054 - val_loss: 0.0440\n",
      "Epoch 457/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0054 - val_loss: 0.0424\n",
      "Epoch 458/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0054 - val_loss: 0.0426\n",
      "Epoch 459/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0055 - val_loss: 0.0430\n",
      "Epoch 460/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0054 - val_loss: 0.0421\n",
      "Epoch 461/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0054 - val_loss: 0.0428\n",
      "Epoch 462/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0054 - val_loss: 0.0403\n",
      "Epoch 463/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0053 - val_loss: 0.0406\n",
      "Epoch 464/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0055 - val_loss: 0.0403\n",
      "Epoch 465/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0055 - val_loss: 0.0437\n",
      "Epoch 466/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0053 - val_loss: 0.0418\n",
      "Epoch 467/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0054 - val_loss: 0.0438\n",
      "Epoch 468/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0055 - val_loss: 0.0423\n",
      "Epoch 469/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0053 - val_loss: 0.0424\n",
      "Epoch 470/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0053 - val_loss: 0.0430\n",
      "Epoch 471/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0053 - val_loss: 0.0405\n",
      "Epoch 472/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0055 - val_loss: 0.0453\n",
      "Epoch 473/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0054 - val_loss: 0.0430\n",
      "Epoch 474/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0053 - val_loss: 0.0451\n",
      "Epoch 475/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0053 - val_loss: 0.0439\n",
      "Epoch 476/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0054 - val_loss: 0.0433\n",
      "Epoch 477/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0053 - val_loss: 0.0422\n",
      "Epoch 478/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0053 - val_loss: 0.0447\n",
      "Epoch 479/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0053 - val_loss: 0.0442\n",
      "Epoch 480/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0053 - val_loss: 0.0434\n",
      "Epoch 481/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0053 - val_loss: 0.0460\n",
      "Epoch 482/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0053 - val_loss: 0.0437\n",
      "Epoch 483/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0054 - val_loss: 0.0417\n",
      "Epoch 484/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0053 - val_loss: 0.0440\n",
      "Epoch 485/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0053 - val_loss: 0.0415\n",
      "Epoch 486/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0053 - val_loss: 0.0427\n",
      "Epoch 487/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0054 - val_loss: 0.0405\n",
      "Epoch 488/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0053 - val_loss: 0.0412\n",
      "Epoch 489/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0053 - val_loss: 0.0433\n",
      "Epoch 490/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0054 - val_loss: 0.0435\n",
      "Epoch 491/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0053 - val_loss: 0.0427\n",
      "Epoch 492/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0053 - val_loss: 0.0439\n",
      "Epoch 493/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0053 - val_loss: 0.0431\n",
      "Epoch 494/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0054 - val_loss: 0.0450\n",
      "Epoch 495/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0053 - val_loss: 0.0453\n",
      "Epoch 496/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0053 - val_loss: 0.0439\n",
      "Epoch 497/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0053 - val_loss: 0.0429\n",
      "Epoch 498/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0054 - val_loss: 0.0442\n",
      "Epoch 499/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0053 - val_loss: 0.0426\n",
      "Epoch 500/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0053 - val_loss: 0.0441\n",
      "Epoch 501/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0053 - val_loss: 0.0427\n",
      "Epoch 502/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0052 - val_loss: 0.0425\n",
      "Epoch 503/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0053 - val_loss: 0.0435\n",
      "Epoch 504/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0052 - val_loss: 0.0424\n",
      "Epoch 505/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0052 - val_loss: 0.0438\n",
      "Epoch 506/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0052 - val_loss: 0.0439\n",
      "Epoch 507/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0054 - val_loss: 0.0442\n",
      "Epoch 508/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0052 - val_loss: 0.0453\n",
      "Epoch 509/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0052 - val_loss: 0.0445\n",
      "Epoch 510/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0053 - val_loss: 0.0450\n",
      "Epoch 511/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0053 - val_loss: 0.0522\n",
      "Epoch 512/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0054 - val_loss: 0.0423\n",
      "Epoch 513/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0053 - val_loss: 0.0446\n",
      "Epoch 514/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0052 - val_loss: 0.0449\n",
      "Epoch 515/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0052 - val_loss: 0.0449\n",
      "Epoch 516/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0053 - val_loss: 0.0416\n",
      "Epoch 517/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0052 - val_loss: 0.0429\n",
      "Epoch 518/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0052 - val_loss: 0.0420\n",
      "Epoch 519/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0052 - val_loss: 0.0440\n",
      "Epoch 520/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0053 - val_loss: 0.0430\n",
      "Epoch 521/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0052 - val_loss: 0.0432\n",
      "Epoch 522/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0054 - val_loss: 0.0441\n",
      "Epoch 523/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0052 - val_loss: 0.0445\n",
      "Epoch 524/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0052 - val_loss: 0.0466\n",
      "Epoch 525/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0052 - val_loss: 0.0415\n",
      "Epoch 526/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0052 - val_loss: 0.0438\n",
      "Epoch 527/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0051 - val_loss: 0.0446\n",
      "Epoch 528/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0051 - val_loss: 0.0442\n",
      "Epoch 529/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0053 - val_loss: 0.0443\n",
      "Epoch 530/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0052 - val_loss: 0.0436\n",
      "Epoch 531/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0052 - val_loss: 0.0428\n",
      "Epoch 532/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0052 - val_loss: 0.0431\n",
      "Epoch 533/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0052 - val_loss: 0.0433\n",
      "Epoch 534/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0052 - val_loss: 0.0446\n",
      "Epoch 535/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0051 - val_loss: 0.0454\n",
      "Epoch 536/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0051 - val_loss: 0.0425\n",
      "Epoch 537/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0052 - val_loss: 0.0451\n",
      "Epoch 538/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0052 - val_loss: 0.0445\n",
      "Epoch 539/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0052 - val_loss: 0.0428\n",
      "Epoch 540/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0053 - val_loss: 0.0455\n",
      "Epoch 541/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0052 - val_loss: 0.0415\n",
      "Epoch 542/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0053 - val_loss: 0.0408\n",
      "Epoch 543/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0052 - val_loss: 0.0426\n",
      "Epoch 544/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0052 - val_loss: 0.0428\n",
      "Epoch 545/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0051 - val_loss: 0.0423\n",
      "Epoch 546/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0051 - val_loss: 0.0393\n",
      "Epoch 547/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0052 - val_loss: 0.0461\n",
      "Epoch 548/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0051 - val_loss: 0.0401\n",
      "Epoch 549/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0052 - val_loss: 0.0408\n",
      "Epoch 550/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0052 - val_loss: 0.0383\n",
      "Epoch 551/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0052 - val_loss: 0.0430\n",
      "Epoch 552/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0052 - val_loss: 0.0454\n",
      "Epoch 553/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0051 - val_loss: 0.0441\n",
      "Epoch 554/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0052 - val_loss: 0.0430\n",
      "Epoch 555/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0054 - val_loss: 0.0445\n",
      "Epoch 556/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0052 - val_loss: 0.0410\n",
      "Epoch 557/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0051 - val_loss: 0.0409\n",
      "Epoch 558/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0052 - val_loss: 0.0400\n",
      "Epoch 559/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0051 - val_loss: 0.0400\n",
      "Epoch 560/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0052 - val_loss: 0.0405\n",
      "Epoch 561/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0052 - val_loss: 0.0415\n",
      "Epoch 562/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0051 - val_loss: 0.0409\n",
      "Epoch 563/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0051 - val_loss: 0.0425\n",
      "Epoch 564/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0051 - val_loss: 0.0383\n",
      "Epoch 565/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0051 - val_loss: 0.0388\n",
      "Epoch 566/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0050 - val_loss: 0.0401\n",
      "Epoch 567/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0051 - val_loss: 0.0395\n",
      "Epoch 568/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0052 - val_loss: 0.0413\n",
      "Epoch 569/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0052 - val_loss: 0.0390\n",
      "Epoch 570/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0052 - val_loss: 0.0397\n",
      "Epoch 571/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0051 - val_loss: 0.0392\n",
      "Epoch 572/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0051 - val_loss: 0.0407\n",
      "Epoch 573/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0051 - val_loss: 0.0390\n",
      "Epoch 574/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0051 - val_loss: 0.0392\n",
      "Epoch 575/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0051 - val_loss: 0.0397\n",
      "Epoch 576/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0051 - val_loss: 0.0412\n",
      "Epoch 577/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0051 - val_loss: 0.0384\n",
      "Epoch 578/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0052 - val_loss: 0.0397\n",
      "Epoch 579/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0051 - val_loss: 0.0390\n",
      "Epoch 580/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0051 - val_loss: 0.0378\n",
      "Epoch 581/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0051 - val_loss: 0.0384\n",
      "Epoch 582/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0050 - val_loss: 0.0377\n",
      "Epoch 583/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0051 - val_loss: 0.0420\n",
      "Epoch 584/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0051 - val_loss: 0.0385\n",
      "Epoch 585/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0051 - val_loss: 0.0409\n",
      "Epoch 586/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0051 - val_loss: 0.0392\n",
      "Epoch 587/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0051 - val_loss: 0.0377\n",
      "Epoch 588/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0051 - val_loss: 0.0392\n",
      "Epoch 589/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0051 - val_loss: 0.0379\n",
      "Epoch 590/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0051 - val_loss: 0.0384\n",
      "Epoch 591/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0051 - val_loss: 0.0385\n",
      "Epoch 592/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0050 - val_loss: 0.0421\n",
      "Epoch 593/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0052 - val_loss: 0.0411\n",
      "Epoch 594/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0050 - val_loss: 0.0407\n",
      "Epoch 595/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0050 - val_loss: 0.0414\n",
      "Epoch 596/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0051 - val_loss: 0.0428\n",
      "Epoch 597/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0052 - val_loss: 0.0444\n",
      "Epoch 598/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0050 - val_loss: 0.0400\n",
      "Epoch 599/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0051 - val_loss: 0.0401\n",
      "Epoch 600/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0051 - val_loss: 0.0405\n",
      "Epoch 601/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0051 - val_loss: 0.0399\n",
      "Epoch 602/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0051 - val_loss: 0.0404\n",
      "Epoch 603/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0051 - val_loss: 0.0410\n",
      "Epoch 604/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0050 - val_loss: 0.0397\n",
      "Epoch 605/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0051 - val_loss: 0.0388\n",
      "Epoch 606/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0052 - val_loss: 0.0406\n",
      "Epoch 607/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0051 - val_loss: 0.0412\n",
      "Epoch 608/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0050 - val_loss: 0.0405\n",
      "Epoch 609/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0051 - val_loss: 0.0402\n",
      "Epoch 610/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0050 - val_loss: 0.0388\n",
      "Epoch 611/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0050 - val_loss: 0.0397\n",
      "Epoch 612/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0050 - val_loss: 0.0372\n",
      "Epoch 613/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0051 - val_loss: 0.0395\n",
      "Epoch 614/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0050 - val_loss: 0.0390\n",
      "Epoch 615/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0051 - val_loss: 0.0378\n",
      "Epoch 616/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0050 - val_loss: 0.0391\n",
      "Epoch 617/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0051 - val_loss: 0.0391\n",
      "Epoch 618/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0050 - val_loss: 0.0382\n",
      "Epoch 619/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0050 - val_loss: 0.0412\n",
      "Epoch 620/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0050 - val_loss: 0.0387\n",
      "Epoch 621/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0051 - val_loss: 0.0398\n",
      "Epoch 622/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0050 - val_loss: 0.0409\n",
      "Epoch 623/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0051 - val_loss: 0.0400\n",
      "Epoch 624/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0050 - val_loss: 0.0400\n",
      "Epoch 625/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0050 - val_loss: 0.0385\n",
      "Epoch 626/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0050 - val_loss: 0.0407\n",
      "Epoch 627/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0050 - val_loss: 0.0391\n",
      "Epoch 628/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0406\n",
      "Epoch 629/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0050 - val_loss: 0.0407\n",
      "Epoch 630/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0051 - val_loss: 0.0415\n",
      "Epoch 631/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0050 - val_loss: 0.0395\n",
      "Epoch 632/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0050 - val_loss: 0.0419\n",
      "Epoch 633/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0049 - val_loss: 0.0405\n",
      "Epoch 634/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0050 - val_loss: 0.0409\n",
      "Epoch 635/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0050 - val_loss: 0.0430\n",
      "Epoch 636/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0051 - val_loss: 0.0388\n",
      "Epoch 637/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0051 - val_loss: 0.0406\n",
      "Epoch 638/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0050 - val_loss: 0.0411\n",
      "Epoch 639/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0398\n",
      "Epoch 640/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0408\n",
      "Epoch 641/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0425\n",
      "Epoch 642/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0051 - val_loss: 0.0420\n",
      "Epoch 643/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0051 - val_loss: 0.0405\n",
      "Epoch 644/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0050 - val_loss: 0.0400\n",
      "Epoch 645/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0420\n",
      "Epoch 646/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0050 - val_loss: 0.0401\n",
      "Epoch 647/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0050 - val_loss: 0.0416\n",
      "Epoch 648/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0051 - val_loss: 0.0410\n",
      "Epoch 649/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0050 - val_loss: 0.0406\n",
      "Epoch 650/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0420\n",
      "Epoch 651/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0050 - val_loss: 0.0431\n",
      "Epoch 652/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0050 - val_loss: 0.0421\n",
      "Epoch 653/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0439\n",
      "Epoch 654/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0050 - val_loss: 0.0446\n",
      "Epoch 655/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0050 - val_loss: 0.0421\n",
      "Epoch 656/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0049 - val_loss: 0.0431\n",
      "Epoch 657/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0050 - val_loss: 0.0418\n",
      "Epoch 658/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0050 - val_loss: 0.0406\n",
      "Epoch 659/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0049 - val_loss: 0.0433\n",
      "Epoch 660/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0050 - val_loss: 0.0425\n",
      "Epoch 661/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0050 - val_loss: 0.0418\n",
      "Epoch 662/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0413\n",
      "Epoch 663/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0051 - val_loss: 0.0422\n",
      "Epoch 664/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0049 - val_loss: 0.0429\n",
      "Epoch 665/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0050 - val_loss: 0.0437\n",
      "Epoch 666/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0438\n",
      "Epoch 667/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0049 - val_loss: 0.0414\n",
      "Epoch 668/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0050 - val_loss: 0.0400\n",
      "Epoch 669/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0050 - val_loss: 0.0439\n",
      "Epoch 670/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0050 - val_loss: 0.0411\n",
      "Epoch 671/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0412\n",
      "Epoch 672/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0404\n",
      "Epoch 673/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0415\n",
      "Epoch 674/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0050 - val_loss: 0.0419\n",
      "Epoch 675/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0050 - val_loss: 0.0417\n",
      "Epoch 676/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0402\n",
      "Epoch 677/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0391\n",
      "Epoch 678/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0454\n",
      "Epoch 679/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0407\n",
      "Epoch 680/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0433\n",
      "Epoch 681/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0419\n",
      "Epoch 682/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0050 - val_loss: 0.0444\n",
      "Epoch 683/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0430\n",
      "Epoch 684/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0050 - val_loss: 0.0413\n",
      "Epoch 685/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0426\n",
      "Epoch 686/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0406\n",
      "Epoch 687/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0408\n",
      "Epoch 688/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0416\n",
      "Epoch 689/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0050 - val_loss: 0.0440\n",
      "Epoch 690/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0407\n",
      "Epoch 691/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0425\n",
      "Epoch 692/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0428\n",
      "Epoch 693/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0402\n",
      "Epoch 694/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0401\n",
      "Epoch 695/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0423\n",
      "Epoch 696/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0435\n",
      "Epoch 697/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0386\n",
      "Epoch 698/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0402\n",
      "Epoch 699/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0050 - val_loss: 0.0421\n",
      "Epoch 700/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0051 - val_loss: 0.0434\n",
      "Epoch 701/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0402\n",
      "Epoch 702/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0409\n",
      "Epoch 703/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0429\n",
      "Epoch 704/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0405\n",
      "Epoch 705/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0050 - val_loss: 0.0419\n",
      "Epoch 706/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0049 - val_loss: 0.0414\n",
      "Epoch 707/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0423\n",
      "Epoch 708/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0438\n",
      "Epoch 709/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0450\n",
      "Epoch 710/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0430\n",
      "Epoch 711/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0049 - val_loss: 0.0419\n",
      "Epoch 712/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0050 - val_loss: 0.0440\n",
      "Epoch 713/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0050 - val_loss: 0.0414\n",
      "Epoch 714/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0431\n",
      "Epoch 715/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0426\n",
      "Epoch 716/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0439\n",
      "Epoch 717/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0401\n",
      "Epoch 718/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0424\n",
      "Epoch 719/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0417\n",
      "Epoch 720/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0414\n",
      "Epoch 721/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0417\n",
      "Epoch 722/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0049 - val_loss: 0.0428\n",
      "Epoch 723/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0449\n",
      "Epoch 724/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0441\n",
      "Epoch 725/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0429\n",
      "Epoch 726/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0426\n",
      "Epoch 727/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0440\n",
      "Epoch 728/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0447\n",
      "Epoch 729/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0418\n",
      "Epoch 730/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0440\n",
      "Epoch 731/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0455\n",
      "Epoch 732/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0473\n",
      "Epoch 733/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0494\n",
      "Epoch 734/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0454\n",
      "Epoch 735/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0449\n",
      "Epoch 736/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0454\n",
      "Epoch 737/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0523\n",
      "Epoch 738/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0475\n",
      "Epoch 739/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0467\n",
      "Epoch 740/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0473\n",
      "Epoch 741/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0496\n",
      "Epoch 742/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0047 - val_loss: 0.0451\n",
      "Epoch 743/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0478\n",
      "Epoch 744/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0453\n",
      "Epoch 745/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0476\n",
      "Epoch 746/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0452\n",
      "Epoch 747/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0483\n",
      "Epoch 748/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0475\n",
      "Epoch 749/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0047 - val_loss: 0.0465\n",
      "Epoch 750/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0456\n",
      "Epoch 751/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0471\n",
      "Epoch 752/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0498\n",
      "Epoch 753/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0446\n",
      "Epoch 754/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0049 - val_loss: 0.0453\n",
      "Epoch 755/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0486\n",
      "Epoch 756/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0050 - val_loss: 0.0442\n",
      "Epoch 757/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0478\n",
      "Epoch 758/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0050 - val_loss: 0.0443\n",
      "Epoch 759/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0447\n",
      "Epoch 760/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0436\n",
      "Epoch 761/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0464\n",
      "Epoch 762/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0485\n",
      "Epoch 763/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0458\n",
      "Epoch 764/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0047 - val_loss: 0.0467\n",
      "Epoch 765/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0472\n",
      "Epoch 766/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0047 - val_loss: 0.0487\n",
      "Epoch 767/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0474\n",
      "Epoch 768/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0048 - val_loss: 0.0449\n",
      "Epoch 769/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0047 - val_loss: 0.0414\n",
      "Epoch 770/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0456\n",
      "Epoch 771/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0048 - val_loss: 0.0447\n",
      "Epoch 772/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0047 - val_loss: 0.0442\n",
      "Epoch 773/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0048 - val_loss: 0.0440\n",
      "Epoch 774/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0468\n",
      "Epoch 775/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0413\n",
      "Epoch 776/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0434\n",
      "Epoch 777/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0048 - val_loss: 0.0425\n",
      "Epoch 778/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0452\n",
      "Epoch 779/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0444\n",
      "Epoch 780/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0048 - val_loss: 0.0433\n",
      "Epoch 781/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0047 - val_loss: 0.0409\n",
      "Epoch 782/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0459\n",
      "Epoch 783/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0048 - val_loss: 0.0428\n",
      "Epoch 784/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0048 - val_loss: 0.0413\n",
      "Epoch 785/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0423\n",
      "Epoch 786/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0438\n",
      "Epoch 787/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0047 - val_loss: 0.0443\n",
      "Epoch 788/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0425\n",
      "Epoch 789/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0047 - val_loss: 0.0446\n",
      "Epoch 790/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0049 - val_loss: 0.0439\n",
      "Epoch 791/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0440\n",
      "Epoch 792/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0047 - val_loss: 0.0446\n",
      "Epoch 793/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0468\n",
      "Epoch 794/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0047 - val_loss: 0.0448\n",
      "Epoch 795/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0442\n",
      "Epoch 796/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0047 - val_loss: 0.0464\n",
      "Epoch 797/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0047 - val_loss: 0.0453\n",
      "Epoch 798/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0472\n",
      "Epoch 799/10000\n",
      "249/249 [==============================] - 2s 10ms/step - loss: 0.0047 - val_loss: 0.0452\n",
      "Epoch 800/10000\n",
      "249/249 [==============================] - 2s 9ms/step - loss: 0.0047 - val_loss: 0.0458\n",
      "Epoch 801/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0047 - val_loss: 0.0454\n",
      "Epoch 802/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0047 - val_loss: 0.0448\n",
      "Epoch 803/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0048 - val_loss: 0.0463\n",
      "Epoch 804/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0047 - val_loss: 0.0451\n",
      "Epoch 805/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0444\n",
      "Epoch 806/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0445\n",
      "Epoch 807/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0048 - val_loss: 0.0442\n",
      "Epoch 808/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0425\n",
      "Epoch 809/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0047 - val_loss: 0.0411\n",
      "Epoch 810/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0047 - val_loss: 0.0408\n",
      "Epoch 811/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0047 - val_loss: 0.0405\n",
      "Epoch 812/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0414\n",
      "Epoch 813/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0049 - val_loss: 0.0406\n",
      "Epoch 814/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0048 - val_loss: 0.0448\n",
      "Epoch 815/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0444\n",
      "Epoch 816/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0449\n",
      "Epoch 817/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0403\n",
      "Epoch 818/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0408\n",
      "Epoch 819/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0048 - val_loss: 0.0413\n",
      "Epoch 820/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0417\n",
      "Epoch 821/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0047 - val_loss: 0.0473\n",
      "Epoch 822/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0047 - val_loss: 0.0427\n",
      "Epoch 823/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0047 - val_loss: 0.0446\n",
      "Epoch 824/10000\n",
      "249/249 [==============================] - 2s 8ms/step - loss: 0.0047 - val_loss: 0.0418\n",
      "Epoch 825/10000\n",
      "249/249 [==============================] - 3s 10ms/step - loss: 0.0047 - val_loss: 0.0443\n",
      "Epoch 826/10000\n",
      "249/249 [==============================] - 2s 9ms/step - loss: 0.0047 - val_loss: 0.0427\n",
      "Epoch 827/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0048 - val_loss: 0.0428\n",
      "Epoch 828/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0047 - val_loss: 0.0442\n",
      "Epoch 829/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0047 - val_loss: 0.0424\n",
      "Epoch 830/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0047 - val_loss: 0.0456\n",
      "Epoch 831/10000\n",
      "249/249 [==============================] - 2s 8ms/step - loss: 0.0048 - val_loss: 0.0451\n",
      "Epoch 832/10000\n",
      "249/249 [==============================] - 2s 8ms/step - loss: 0.0046 - val_loss: 0.0429\n",
      "Epoch 833/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0412\n",
      "Epoch 834/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0452\n",
      "Epoch 835/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0439\n",
      "Epoch 836/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0047 - val_loss: 0.0463\n",
      "Epoch 837/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0047 - val_loss: 0.0427\n",
      "Epoch 838/10000\n",
      "249/249 [==============================] - 2s 8ms/step - loss: 0.0048 - val_loss: 0.0407\n",
      "Epoch 839/10000\n",
      "249/249 [==============================] - 2s 9ms/step - loss: 0.0047 - val_loss: 0.0390\n",
      "Epoch 840/10000\n",
      "249/249 [==============================] - 3s 10ms/step - loss: 0.0047 - val_loss: 0.0433\n",
      "Epoch 841/10000\n",
      "249/249 [==============================] - 3s 12ms/step - loss: 0.0047 - val_loss: 0.0409\n",
      "Epoch 842/10000\n",
      "249/249 [==============================] - 2s 9ms/step - loss: 0.0047 - val_loss: 0.0410\n",
      "Epoch 843/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0413\n",
      "Epoch 844/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0046 - val_loss: 0.0399\n",
      "Epoch 845/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0407\n",
      "Epoch 846/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0410\n",
      "Epoch 847/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0048 - val_loss: 0.0414\n",
      "Epoch 848/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0047 - val_loss: 0.0402\n",
      "Epoch 849/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0047 - val_loss: 0.0413\n",
      "Epoch 850/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0047 - val_loss: 0.0385\n",
      "Epoch 851/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0047 - val_loss: 0.0380\n",
      "Epoch 852/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0048 - val_loss: 0.0405\n",
      "Epoch 853/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0048 - val_loss: 0.0394\n",
      "Epoch 854/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0047 - val_loss: 0.0402\n",
      "Epoch 855/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0047 - val_loss: 0.0404\n",
      "Epoch 856/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0047 - val_loss: 0.0392\n",
      "Epoch 857/10000\n",
      "249/249 [==============================] - 2s 8ms/step - loss: 0.0046 - val_loss: 0.0407\n",
      "Epoch 858/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0046 - val_loss: 0.0399\n",
      "Epoch 859/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0046 - val_loss: 0.0385\n",
      "Epoch 860/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0046 - val_loss: 0.0398\n",
      "Epoch 861/10000\n",
      "249/249 [==============================] - 2s 9ms/step - loss: 0.0048 - val_loss: 0.0412\n",
      "Epoch 862/10000\n",
      "249/249 [==============================] - 2s 8ms/step - loss: 0.0046 - val_loss: 0.0391\n",
      "Epoch 863/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0383\n",
      "Epoch 864/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0047 - val_loss: 0.0399\n",
      "Epoch 865/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0414\n",
      "Epoch 866/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0408\n",
      "Epoch 867/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0047 - val_loss: 0.0393\n",
      "Epoch 868/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0398\n",
      "Epoch 869/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0390\n",
      "Epoch 870/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0402\n",
      "Epoch 871/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0374\n",
      "Epoch 872/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0404\n",
      "Epoch 873/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0395\n",
      "Epoch 874/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0418\n",
      "Epoch 875/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0388\n",
      "Epoch 876/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0426\n",
      "Epoch 877/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0047 - val_loss: 0.0394\n",
      "Epoch 878/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0047 - val_loss: 0.0398\n",
      "Epoch 879/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0047 - val_loss: 0.0395\n",
      "Epoch 880/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0046 - val_loss: 0.0402\n",
      "Epoch 881/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0402\n",
      "Epoch 882/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0394\n",
      "Epoch 883/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0420\n",
      "Epoch 884/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0046 - val_loss: 0.0413\n",
      "Epoch 885/10000\n",
      "249/249 [==============================] - 2s 9ms/step - loss: 0.0047 - val_loss: 0.0425\n",
      "Epoch 886/10000\n",
      "249/249 [==============================] - 2s 9ms/step - loss: 0.0047 - val_loss: 0.0421\n",
      "Epoch 887/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0046 - val_loss: 0.0391\n",
      "Epoch 888/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0046 - val_loss: 0.0457\n",
      "Epoch 889/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0413\n",
      "Epoch 890/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0047 - val_loss: 0.0405\n",
      "Epoch 891/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0403\n",
      "Epoch 892/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0412\n",
      "Epoch 893/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0434\n",
      "Epoch 894/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0397\n",
      "Epoch 895/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0046 - val_loss: 0.0419\n",
      "Epoch 896/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0416\n",
      "Epoch 897/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0046 - val_loss: 0.0392\n",
      "Epoch 898/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0046 - val_loss: 0.0401\n",
      "Epoch 899/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0047 - val_loss: 0.0401\n",
      "Epoch 900/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0046 - val_loss: 0.0412\n",
      "Epoch 901/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0399\n",
      "Epoch 902/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0409\n",
      "Epoch 903/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0046 - val_loss: 0.0455\n",
      "Epoch 904/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0046 - val_loss: 0.0412\n",
      "Epoch 905/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0439\n",
      "Epoch 906/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0421\n",
      "Epoch 907/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0427\n",
      "Epoch 908/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0402\n",
      "Epoch 909/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0425\n",
      "Epoch 910/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0047 - val_loss: 0.0404\n",
      "Epoch 911/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0397\n",
      "Epoch 912/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0390\n",
      "Epoch 913/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0405\n",
      "Epoch 914/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0431\n",
      "Epoch 915/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0413\n",
      "Epoch 916/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0420\n",
      "Epoch 917/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0404\n",
      "Epoch 918/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0392\n",
      "Epoch 919/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0413\n",
      "Epoch 920/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0428\n",
      "Epoch 921/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0048 - val_loss: 0.0393\n",
      "Epoch 922/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0417\n",
      "Epoch 923/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0424\n",
      "Epoch 924/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0440\n",
      "Epoch 925/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0418\n",
      "Epoch 926/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0437\n",
      "Epoch 927/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0425\n",
      "Epoch 928/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0420\n",
      "Epoch 929/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0423\n",
      "Epoch 930/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0426\n",
      "Epoch 931/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0045 - val_loss: 0.0416\n",
      "Epoch 932/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0406\n",
      "Epoch 933/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0400\n",
      "Epoch 934/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0422\n",
      "Epoch 935/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0428\n",
      "Epoch 936/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0408\n",
      "Epoch 937/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0420\n",
      "Epoch 938/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0434\n",
      "Epoch 939/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0432\n",
      "Epoch 940/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0392\n",
      "Epoch 941/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0402\n",
      "Epoch 942/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0416\n",
      "Epoch 943/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0045 - val_loss: 0.0394\n",
      "Epoch 944/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0046 - val_loss: 0.0382\n",
      "Epoch 945/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0046 - val_loss: 0.0420\n",
      "Epoch 946/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0394\n",
      "Epoch 947/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0402\n",
      "Epoch 948/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0391\n",
      "Epoch 949/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0406\n",
      "Epoch 950/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0396\n",
      "Epoch 951/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0404\n",
      "Epoch 952/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0419\n",
      "Epoch 953/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0408\n",
      "Epoch 954/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0382\n",
      "Epoch 955/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0409\n",
      "Epoch 956/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0406\n",
      "Epoch 957/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0382\n",
      "Epoch 958/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0399\n",
      "Epoch 959/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0399\n",
      "Epoch 960/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0395\n",
      "Epoch 961/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0381\n",
      "Epoch 962/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0432\n",
      "Epoch 963/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0045 - val_loss: 0.0413\n",
      "Epoch 964/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0045 - val_loss: 0.0417\n",
      "Epoch 965/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0045 - val_loss: 0.0399\n",
      "Epoch 966/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0045 - val_loss: 0.0429\n",
      "Epoch 967/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0418\n",
      "Epoch 968/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0046 - val_loss: 0.0402\n",
      "Epoch 969/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0046 - val_loss: 0.0431\n",
      "Epoch 970/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0403\n",
      "Epoch 971/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0405\n",
      "Epoch 972/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0387\n",
      "Epoch 973/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0387\n",
      "Epoch 974/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0385\n",
      "Epoch 975/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0415\n",
      "Epoch 976/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0400\n",
      "Epoch 977/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0399\n",
      "Epoch 978/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0384\n",
      "Epoch 979/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0393\n",
      "Epoch 980/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0402\n",
      "Epoch 981/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0441\n",
      "Epoch 982/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0408\n",
      "Epoch 983/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0420\n",
      "Epoch 984/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0401\n",
      "Epoch 985/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0426\n",
      "Epoch 986/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0415\n",
      "Epoch 987/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0409\n",
      "Epoch 988/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0404\n",
      "Epoch 989/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0415\n",
      "Epoch 990/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0409\n",
      "Epoch 991/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0412\n",
      "Epoch 992/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0408\n",
      "Epoch 993/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0393\n",
      "Epoch 994/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0404\n",
      "Epoch 995/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0388\n",
      "Epoch 996/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0424\n",
      "Epoch 997/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0407\n",
      "Epoch 998/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0406\n",
      "Epoch 999/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0407\n",
      "Epoch 1000/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0377\n",
      "Epoch 1001/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0392\n",
      "Epoch 1002/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0432\n",
      "Epoch 1003/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0413\n",
      "Epoch 1004/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0405\n",
      "Epoch 1005/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0393\n",
      "Epoch 1006/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0405\n",
      "Epoch 1007/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0410\n",
      "Epoch 1008/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0421\n",
      "Epoch 1009/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0406\n",
      "Epoch 1010/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0046 - val_loss: 0.0417\n",
      "Epoch 1011/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0429\n",
      "Epoch 1012/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0418\n",
      "Epoch 1013/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0407\n",
      "Epoch 1014/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0373\n",
      "Epoch 1015/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0408\n",
      "Epoch 1016/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0045 - val_loss: 0.0375\n",
      "Epoch 1017/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0392\n",
      "Epoch 1018/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0404\n",
      "Epoch 1019/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0390\n",
      "Epoch 1020/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0389\n",
      "Epoch 1021/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0046 - val_loss: 0.0392\n",
      "Epoch 1022/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0375\n",
      "Epoch 1023/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0401\n",
      "Epoch 1024/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0384\n",
      "Epoch 1025/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0400\n",
      "Epoch 1026/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0374\n",
      "Epoch 1027/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0397\n",
      "Epoch 1028/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0381\n",
      "Epoch 1029/10000\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0389\n",
      "Epoch 1030/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0378\n",
      "Epoch 1031/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0407\n",
      "Epoch 1032/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0379\n",
      "Epoch 1033/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0393\n",
      "Epoch 1034/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0395\n",
      "Epoch 1035/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0385\n",
      "Epoch 1036/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0369\n",
      "Epoch 1037/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0368\n",
      "Epoch 1038/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0405\n",
      "Epoch 1039/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0407\n",
      "Epoch 1040/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0383\n",
      "Epoch 1041/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0387\n",
      "Epoch 1042/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0405\n",
      "Epoch 1043/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0045 - val_loss: 0.0378\n",
      "Epoch 1044/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0376\n",
      "Epoch 1045/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0414\n",
      "Epoch 1046/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0398\n",
      "Epoch 1047/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0393\n",
      "Epoch 1048/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0401\n",
      "Epoch 1049/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0387\n",
      "Epoch 1050/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0394\n",
      "Epoch 1051/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0393\n",
      "Epoch 1052/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0385\n",
      "Epoch 1053/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0384\n",
      "Epoch 1054/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0387\n",
      "Epoch 1055/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0392\n",
      "Epoch 1056/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0393\n",
      "Epoch 1057/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0421\n",
      "Epoch 1058/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0402\n",
      "Epoch 1059/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0396\n",
      "Epoch 1060/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0383\n",
      "Epoch 1061/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0420\n",
      "Epoch 1062/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0407\n",
      "Epoch 1063/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0378\n",
      "Epoch 1064/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0384\n",
      "Epoch 1065/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0393\n",
      "Epoch 1066/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0379\n",
      "Epoch 1067/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0413\n",
      "Epoch 1068/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0380\n",
      "Epoch 1069/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0406\n",
      "Epoch 1070/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0384\n",
      "Epoch 1071/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0386\n",
      "Epoch 1072/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0404\n",
      "Epoch 1073/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0410\n",
      "Epoch 1074/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0418\n",
      "Epoch 1075/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0412\n",
      "Epoch 1076/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0412\n",
      "Epoch 1077/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0046 - val_loss: 0.0413\n",
      "Epoch 1078/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0407\n",
      "Epoch 1079/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0045 - val_loss: 0.0396\n",
      "Epoch 1080/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0396\n",
      "Epoch 1081/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0384\n",
      "Epoch 1082/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0402\n",
      "Epoch 1083/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0386\n",
      "Epoch 1084/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0398\n",
      "Epoch 1085/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0411\n",
      "Epoch 1086/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0410\n",
      "Epoch 1087/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0045 - val_loss: 0.0392\n",
      "Epoch 1088/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0419\n",
      "Epoch 1089/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0045 - val_loss: 0.0373\n",
      "Epoch 1090/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0384\n",
      "Epoch 1091/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0374\n",
      "Epoch 1092/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0389\n",
      "Epoch 1093/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0373\n",
      "Epoch 1094/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0382\n",
      "Epoch 1095/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0379\n",
      "Epoch 1096/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0380\n",
      "Epoch 1097/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0373\n",
      "Epoch 1098/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0398\n",
      "Epoch 1099/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0393\n",
      "Epoch 1100/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0392\n",
      "Epoch 1101/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0394\n",
      "Epoch 1102/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0403\n",
      "Epoch 1103/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0394\n",
      "Epoch 1104/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0383\n",
      "Epoch 1105/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0369\n",
      "Epoch 1106/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0395\n",
      "Epoch 1107/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0399\n",
      "Epoch 1108/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0392\n",
      "Epoch 1109/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0375\n",
      "Epoch 1110/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0363\n",
      "Epoch 1111/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0045 - val_loss: 0.0397\n",
      "Epoch 1112/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0389\n",
      "Epoch 1113/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0391\n",
      "Epoch 1114/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0393\n",
      "Epoch 1115/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0376\n",
      "Epoch 1116/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0384\n",
      "Epoch 1117/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0381\n",
      "Epoch 1118/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0399\n",
      "Epoch 1119/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0045 - val_loss: 0.0385\n",
      "Epoch 1120/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0045 - val_loss: 0.0396\n",
      "Epoch 1121/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0045 - val_loss: 0.0380\n",
      "Epoch 1122/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0046 - val_loss: 0.0380\n",
      "Epoch 1123/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0383\n",
      "Epoch 1124/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0386\n",
      "Epoch 1125/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0381\n",
      "Epoch 1126/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0382\n",
      "Epoch 1127/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0395\n",
      "Epoch 1128/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0391\n",
      "Epoch 1129/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0380\n",
      "Epoch 1130/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0045 - val_loss: 0.0366\n",
      "Epoch 1131/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0382\n",
      "Epoch 1132/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0374\n",
      "Epoch 1133/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0376\n",
      "Epoch 1134/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0380\n",
      "Epoch 1135/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0394\n",
      "Epoch 1136/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0381\n",
      "Epoch 1137/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0384\n",
      "Epoch 1138/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0382\n",
      "Epoch 1139/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0390\n",
      "Epoch 1140/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0397\n",
      "Epoch 1141/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0378\n",
      "Epoch 1142/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0393\n",
      "Epoch 1143/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0390\n",
      "Epoch 1144/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0383\n",
      "Epoch 1145/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0374\n",
      "Epoch 1146/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0383\n",
      "Epoch 1147/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0373\n",
      "Epoch 1148/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0045 - val_loss: 0.0390\n",
      "Epoch 1149/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0380\n",
      "Epoch 1150/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0380\n",
      "Epoch 1151/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0045 - val_loss: 0.0379\n",
      "Epoch 1152/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0373\n",
      "Epoch 1153/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0395\n",
      "Epoch 1154/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0404\n",
      "Epoch 1155/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0369\n",
      "Epoch 1156/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0370\n",
      "Epoch 1157/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0375\n",
      "Epoch 1158/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0376\n",
      "Epoch 1159/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0390\n",
      "Epoch 1160/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0379\n",
      "Epoch 1161/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0380\n",
      "Epoch 1162/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0045 - val_loss: 0.0375\n",
      "Epoch 1163/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0379\n",
      "Epoch 1164/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0385\n",
      "Epoch 1165/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0386\n",
      "Epoch 1166/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0378\n",
      "Epoch 1167/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0376\n",
      "Epoch 1168/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0385\n",
      "Epoch 1169/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0388\n",
      "Epoch 1170/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0392\n",
      "Epoch 1171/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0390\n",
      "Epoch 1172/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0395\n",
      "Epoch 1173/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0388\n",
      "Epoch 1174/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0381\n",
      "Epoch 1175/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0045 - val_loss: 0.0380\n",
      "Epoch 1176/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0393\n",
      "Epoch 1177/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0378\n",
      "Epoch 1178/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0400\n",
      "Epoch 1179/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0385\n",
      "Epoch 1180/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0386\n",
      "Epoch 1181/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0381\n",
      "Epoch 1182/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0391\n",
      "Epoch 1183/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0395\n",
      "Epoch 1184/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0045 - val_loss: 0.0391\n",
      "Epoch 1185/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0392\n",
      "Epoch 1186/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0390\n",
      "Epoch 1187/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0377\n",
      "Epoch 1188/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0388\n",
      "Epoch 1189/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0383\n",
      "Epoch 1190/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0383\n",
      "Epoch 1191/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0381\n",
      "Epoch 1192/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0365\n",
      "Epoch 1193/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0378\n",
      "Epoch 1194/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0396\n",
      "Epoch 1195/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0045 - val_loss: 0.0373\n",
      "Epoch 1196/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0373\n",
      "Epoch 1197/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0383\n",
      "Epoch 1198/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0378\n",
      "Epoch 1199/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0372\n",
      "Epoch 1200/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0368\n",
      "Epoch 1201/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0390\n",
      "Epoch 1202/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0391\n",
      "Epoch 1203/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0380\n",
      "Epoch 1204/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0379\n",
      "Epoch 1205/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0381\n",
      "Epoch 1206/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0377\n",
      "Epoch 1207/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0045 - val_loss: 0.0378\n",
      "Epoch 1208/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0371\n",
      "Epoch 1209/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0387\n",
      "Epoch 1210/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0385\n",
      "Epoch 1211/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0401\n",
      "Epoch 1212/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0401\n",
      "Epoch 1213/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0400\n",
      "Epoch 1214/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0389\n",
      "Epoch 1215/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0391\n",
      "Epoch 1216/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0382\n",
      "Epoch 1217/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0377\n",
      "Epoch 1218/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0397\n",
      "Epoch 1219/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0382\n",
      "Epoch 1220/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0392\n",
      "Epoch 1221/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0379\n",
      "Epoch 1222/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0379\n",
      "Epoch 1223/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0377\n",
      "Epoch 1224/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0383\n",
      "Epoch 1225/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0376\n",
      "Epoch 1226/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0386\n",
      "Epoch 1227/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0385\n",
      "Epoch 1228/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0390\n",
      "Epoch 1229/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0387\n",
      "Epoch 1230/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0379\n",
      "Epoch 1231/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0389\n",
      "Epoch 1232/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0380\n",
      "Epoch 1233/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0379\n",
      "Epoch 1234/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0384\n",
      "Epoch 1235/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0388\n",
      "Epoch 1236/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0396\n",
      "Epoch 1237/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0380\n",
      "Epoch 1238/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0384\n",
      "Epoch 1239/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0393\n",
      "Epoch 1240/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0382\n",
      "Epoch 1241/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0382\n",
      "Epoch 1242/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0389\n",
      "Epoch 1243/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0384\n",
      "Epoch 1244/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0385\n",
      "Epoch 1245/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0396\n",
      "Epoch 1246/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0369\n",
      "Epoch 1247/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0382\n",
      "Epoch 1248/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0379\n",
      "Epoch 1249/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0391\n",
      "Epoch 1250/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0386\n",
      "Epoch 1251/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0374\n",
      "Epoch 1252/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0401\n",
      "Epoch 1253/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0386\n",
      "Epoch 1254/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0377\n",
      "Epoch 1255/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0392\n",
      "Epoch 1256/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0401\n",
      "Epoch 1257/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0378\n",
      "Epoch 1258/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0387\n",
      "Epoch 1259/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0378\n",
      "Epoch 1260/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0372\n",
      "Epoch 1261/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0385\n",
      "Epoch 1262/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0397\n",
      "Epoch 1263/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0392\n",
      "Epoch 1264/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0388\n",
      "Epoch 1265/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0384\n",
      "Epoch 1266/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0383\n",
      "Epoch 1267/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0391\n",
      "Epoch 1268/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0370\n",
      "Epoch 1269/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0373\n",
      "Epoch 1270/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0380\n",
      "Epoch 1271/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0371\n",
      "Epoch 1272/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0377\n",
      "Epoch 1273/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0389\n",
      "Epoch 1274/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0375\n",
      "Epoch 1275/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0380\n",
      "Epoch 1276/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0373\n",
      "Epoch 1277/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0384\n",
      "Epoch 1278/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0377\n",
      "Epoch 1279/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0399\n",
      "Epoch 1280/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0386\n",
      "Epoch 1281/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0382\n",
      "Epoch 1282/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0403\n",
      "Epoch 1283/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0381\n",
      "Epoch 1284/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0378\n",
      "Epoch 1285/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0366\n",
      "Epoch 1286/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0372\n",
      "Epoch 1287/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0380\n",
      "Epoch 1288/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0373\n",
      "Epoch 1289/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0391\n",
      "Epoch 1290/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0385\n",
      "Epoch 1291/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0388\n",
      "Epoch 1292/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0382\n",
      "Epoch 1293/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0383\n",
      "Epoch 1294/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0391\n",
      "Epoch 1295/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0379\n",
      "Epoch 1296/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0392\n",
      "Epoch 1297/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0396\n",
      "Epoch 1298/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0388\n",
      "Epoch 1299/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0381\n",
      "Epoch 1300/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0381\n",
      "Epoch 1301/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0391\n",
      "Epoch 1302/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0391\n",
      "Epoch 1303/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0391\n",
      "Epoch 1304/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0382\n",
      "Epoch 1305/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0398\n",
      "Epoch 1306/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0393\n",
      "Epoch 1307/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0388\n",
      "Epoch 1308/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0388\n",
      "Epoch 1309/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0385\n",
      "Epoch 1310/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0391\n",
      "Epoch 1311/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0390\n",
      "Epoch 1312/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0378\n",
      "Epoch 1313/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0394\n",
      "Epoch 1314/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0389\n",
      "Epoch 1315/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0387\n",
      "Epoch 1316/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0378\n",
      "Epoch 1317/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0381\n",
      "Epoch 1318/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0382\n",
      "Epoch 1319/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0375\n",
      "Epoch 1320/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0384\n",
      "Epoch 1321/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0379\n",
      "Epoch 1322/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0385\n",
      "Epoch 1323/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0379\n",
      "Epoch 1324/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0385\n",
      "Epoch 1325/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0388\n",
      "Epoch 1326/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0381\n",
      "Epoch 1327/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0375\n",
      "Epoch 1328/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0373\n",
      "Epoch 1329/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0381\n",
      "Epoch 1330/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0374\n",
      "Epoch 1331/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0384\n",
      "Epoch 1332/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0374\n",
      "Epoch 1333/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0391\n",
      "Epoch 1334/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0392\n",
      "Epoch 1335/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0389\n",
      "Epoch 1336/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0387\n",
      "Epoch 1337/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0381\n",
      "Epoch 1338/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0389\n",
      "Epoch 1339/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0392\n",
      "Epoch 1340/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0378\n",
      "Epoch 1341/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0381\n",
      "Epoch 1342/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0375\n",
      "Epoch 1343/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0376\n",
      "Epoch 1344/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0376\n",
      "Epoch 1345/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0373\n",
      "Epoch 1346/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0381\n",
      "Epoch 1347/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0380\n",
      "Epoch 1348/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0384\n",
      "Epoch 1349/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0374\n",
      "Epoch 1350/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0392\n",
      "Epoch 1351/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0373\n",
      "Epoch 1352/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0382\n",
      "Epoch 1353/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0044 - val_loss: 0.0386\n",
      "Epoch 1354/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0367\n",
      "Epoch 1355/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0375\n",
      "Epoch 1356/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0390\n",
      "Epoch 1357/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0389\n",
      "Epoch 1358/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0370\n",
      "Epoch 1359/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0379\n",
      "Epoch 1360/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0379\n",
      "Epoch 1361/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0381\n",
      "Epoch 1362/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0391\n",
      "Epoch 1363/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0391\n",
      "Epoch 1364/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0393\n",
      "Epoch 1365/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0399\n",
      "Epoch 1366/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0393\n",
      "Epoch 1367/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0393\n",
      "Epoch 1368/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0387\n",
      "Epoch 1369/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0385\n",
      "Epoch 1370/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0383\n",
      "Epoch 1371/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0389\n",
      "Epoch 1372/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0378\n",
      "Epoch 1373/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0374\n",
      "Epoch 1374/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0379\n",
      "Epoch 1375/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0043 - val_loss: 0.0377\n",
      "Epoch 1376/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0370\n",
      "Epoch 1377/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0382\n",
      "Epoch 1378/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0369\n",
      "Epoch 1379/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0385\n",
      "Epoch 1380/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0383\n",
      "Epoch 1381/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0372\n",
      "Epoch 1382/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0372\n",
      "Epoch 1383/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0384\n",
      "Epoch 1384/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0382\n",
      "Epoch 1385/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0380\n",
      "Epoch 1386/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0387\n",
      "Epoch 1387/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0387\n",
      "Epoch 1388/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0379\n",
      "Epoch 1389/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0372\n",
      "Epoch 1390/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0368\n",
      "Epoch 1391/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0381\n",
      "Epoch 1392/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0381\n",
      "Epoch 1393/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0378\n",
      "Epoch 1394/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0379\n",
      "Epoch 1395/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0378\n",
      "Epoch 1396/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0379\n",
      "Epoch 1397/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0365\n",
      "Epoch 1398/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0372\n",
      "Epoch 1399/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0397\n",
      "Epoch 1400/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0384\n",
      "Epoch 1401/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0376\n",
      "Epoch 1402/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0385\n",
      "Epoch 1403/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0375\n",
      "Epoch 1404/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0390\n",
      "Epoch 1405/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0379\n",
      "Epoch 1406/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0376\n",
      "Epoch 1407/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0378\n",
      "Epoch 1408/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0385\n",
      "Epoch 1409/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0383\n",
      "Epoch 1410/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0375\n",
      "Epoch 1411/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0376\n",
      "Epoch 1412/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0388\n",
      "Epoch 1413/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0364\n",
      "Epoch 1414/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0380\n",
      "Epoch 1415/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0382\n",
      "Epoch 1416/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0368\n",
      "Epoch 1417/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0383\n",
      "Epoch 1418/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0375\n",
      "Epoch 1419/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0374\n",
      "Epoch 1420/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0379\n",
      "Epoch 1421/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0366\n",
      "Epoch 1422/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0379\n",
      "Epoch 1423/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0380\n",
      "Epoch 1424/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0368\n",
      "Epoch 1425/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0374\n",
      "Epoch 1426/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0370\n",
      "Epoch 1427/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0387\n",
      "Epoch 1428/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0390\n",
      "Epoch 1429/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0385\n",
      "Epoch 1430/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0383\n",
      "Epoch 1431/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0370\n",
      "Epoch 1432/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0380\n",
      "Epoch 1433/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0377\n",
      "Epoch 1434/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0383\n",
      "Epoch 1435/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0386\n",
      "Epoch 1436/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0370\n",
      "Epoch 1437/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0384\n",
      "Epoch 1438/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0388\n",
      "Epoch 1439/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0374\n",
      "Epoch 1440/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0384\n",
      "Epoch 1441/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0387\n",
      "Epoch 1442/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0381\n",
      "Epoch 1443/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0376\n",
      "Epoch 1444/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0370\n",
      "Epoch 1445/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0389\n",
      "Epoch 1446/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0384\n",
      "Epoch 1447/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0374\n",
      "Epoch 1448/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0378\n",
      "Epoch 1449/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0374\n",
      "Epoch 1450/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0376\n",
      "Epoch 1451/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0384\n",
      "Epoch 1452/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0041 - val_loss: 0.0387\n",
      "Epoch 1453/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0379\n",
      "Epoch 1454/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0383\n",
      "Epoch 1455/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0376\n",
      "Epoch 1456/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0377\n",
      "Epoch 1457/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0041 - val_loss: 0.0371\n",
      "Epoch 1458/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0382\n",
      "Epoch 1459/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0381\n",
      "Epoch 1460/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0041 - val_loss: 0.0379\n",
      "Epoch 1461/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0374\n",
      "Epoch 1462/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0381\n",
      "Epoch 1463/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0384\n",
      "Epoch 1464/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0369\n",
      "Epoch 1465/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0372\n",
      "Epoch 1466/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0383\n",
      "Epoch 1467/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0380\n",
      "Epoch 1468/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0375\n",
      "Epoch 1469/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0378\n",
      "Epoch 1470/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0374\n",
      "Epoch 1471/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0374\n",
      "Epoch 1472/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0379\n",
      "Epoch 1473/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0382\n",
      "Epoch 1474/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0379\n",
      "Epoch 1475/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0363\n",
      "Epoch 1476/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0388\n",
      "Epoch 1477/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0388\n",
      "Epoch 1478/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0390\n",
      "Epoch 1479/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0388\n",
      "Epoch 1480/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0374\n",
      "Epoch 1481/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0366\n",
      "Epoch 1482/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0380\n",
      "Epoch 1483/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0380\n",
      "Epoch 1484/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0378\n",
      "Epoch 1485/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0377\n",
      "Epoch 1486/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0366\n",
      "Epoch 1487/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0377\n",
      "Epoch 1488/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0386\n",
      "Epoch 1489/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0370\n",
      "Epoch 1490/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0384\n",
      "Epoch 1491/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0384\n",
      "Epoch 1492/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0376\n",
      "Epoch 1493/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0042 - val_loss: 0.0371\n",
      "Epoch 1494/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0042 - val_loss: 0.0365\n",
      "Epoch 1495/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0041 - val_loss: 0.0377\n",
      "Epoch 1496/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0380\n",
      "Epoch 1497/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0379\n",
      "Epoch 1498/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0366\n",
      "Epoch 1499/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0387\n",
      "Epoch 1500/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0383\n",
      "Epoch 1501/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0371\n",
      "Epoch 1502/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0389\n",
      "Epoch 1503/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0368\n",
      "Epoch 1504/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0377\n",
      "Epoch 1505/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0372\n",
      "Epoch 1506/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0372\n",
      "Epoch 1507/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0375\n",
      "Epoch 1508/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0377\n",
      "Epoch 1509/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0383\n",
      "Epoch 1510/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0373\n",
      "Epoch 1511/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0368\n",
      "Epoch 1512/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0390\n",
      "Epoch 1513/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0389\n",
      "Epoch 1514/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0390\n",
      "Epoch 1515/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0379\n",
      "Epoch 1516/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0372\n",
      "Epoch 1517/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0380\n",
      "Epoch 1518/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0381\n",
      "Epoch 1519/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0371\n",
      "Epoch 1520/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0373\n",
      "Epoch 1521/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0374\n",
      "Epoch 1522/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0369\n",
      "Epoch 1523/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0371\n",
      "Epoch 1524/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0041 - val_loss: 0.0371\n",
      "Epoch 1525/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0041 - val_loss: 0.0369\n",
      "Epoch 1526/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0042 - val_loss: 0.0367\n",
      "Epoch 1527/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0381\n",
      "Epoch 1528/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0376\n",
      "Epoch 1529/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0372\n",
      "Epoch 1530/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0378\n",
      "Epoch 1531/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0377\n",
      "Epoch 1532/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0388\n",
      "Epoch 1533/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0365\n",
      "Epoch 1534/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0388\n",
      "Epoch 1535/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0389\n",
      "Epoch 1536/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0041 - val_loss: 0.0377\n",
      "Epoch 1537/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0369\n",
      "Epoch 1538/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0383\n",
      "Epoch 1539/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0387\n",
      "Epoch 1540/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0380\n",
      "Epoch 1541/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0376\n",
      "Epoch 1542/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0380\n",
      "Epoch 1543/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0369\n",
      "Epoch 1544/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0382\n",
      "Epoch 1545/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0374\n",
      "Epoch 1546/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0041 - val_loss: 0.0378\n",
      "Epoch 1547/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0378\n",
      "Epoch 1548/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0388\n",
      "Epoch 1549/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0375\n",
      "Epoch 1550/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0374\n",
      "Epoch 1551/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0373\n",
      "Epoch 1552/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0384\n",
      "Epoch 1553/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0373\n",
      "Epoch 1554/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0367\n",
      "Epoch 1555/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0379\n",
      "Epoch 1556/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0381\n",
      "Epoch 1557/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0376\n",
      "Epoch 1558/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0377\n",
      "Epoch 1559/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0369\n",
      "Epoch 1560/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0372\n",
      "Epoch 1561/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0369\n",
      "Epoch 1562/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0375\n",
      "Epoch 1563/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0379\n",
      "Epoch 1564/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0371\n",
      "Epoch 1565/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0384\n",
      "Epoch 1566/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0381\n",
      "Epoch 1567/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0378\n",
      "Epoch 1568/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0384\n",
      "Epoch 1569/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0386\n",
      "Epoch 1570/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0041 - val_loss: 0.0371\n",
      "Epoch 1571/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0375\n",
      "Epoch 1572/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0378\n",
      "Epoch 1573/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0373\n",
      "Epoch 1574/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0379\n",
      "Epoch 1575/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0041 - val_loss: 0.0386\n",
      "Epoch 1576/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0041 - val_loss: 0.0379\n",
      "Epoch 1577/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0041 - val_loss: 0.0374\n",
      "Epoch 1578/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0041 - val_loss: 0.0388\n",
      "Epoch 1579/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0041 - val_loss: 0.0375\n",
      "Epoch 1580/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0381\n",
      "Epoch 1581/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0041 - val_loss: 0.0380\n",
      "Epoch 1582/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0378\n",
      "Epoch 1583/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0381\n",
      "Epoch 1584/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0382\n",
      "Epoch 1585/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0373\n",
      "Epoch 1586/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0386\n",
      "Epoch 1587/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0390\n",
      "Epoch 1588/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0393\n",
      "Epoch 1589/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0373\n",
      "Epoch 1590/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0041 - val_loss: 0.0390\n",
      "Epoch 1591/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0377\n",
      "Epoch 1592/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0385\n",
      "Epoch 1593/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0373\n",
      "Epoch 1594/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0383\n",
      "Epoch 1595/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0372\n",
      "Epoch 1596/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0371\n",
      "Epoch 1597/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0041 - val_loss: 0.0382\n",
      "Epoch 1598/10000\n",
      "249/249 [==============================] - 2s 8ms/step - loss: 0.0041 - val_loss: 0.0377\n",
      "Epoch 1599/10000\n",
      "249/249 [==============================] - 3s 11ms/step - loss: 0.0042 - val_loss: 0.0374\n",
      "Epoch 1600/10000\n",
      "249/249 [==============================] - 2s 8ms/step - loss: 0.0041 - val_loss: 0.0377\n",
      "Epoch 1601/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0042 - val_loss: 0.0383\n",
      "Epoch 1602/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0381\n",
      "Epoch 1603/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0379\n",
      "Epoch 1604/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0380\n",
      "Epoch 1605/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0377\n",
      "Epoch 1606/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0370\n",
      "Epoch 1607/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0373\n",
      "Epoch 1608/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0368\n",
      "Epoch 1609/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0041 - val_loss: 0.0378\n",
      "Epoch 1610/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0042 - val_loss: 0.0380\n",
      "Epoch 1611/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0041 - val_loss: 0.0376\n",
      "Epoch 1612/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0369\n",
      "Epoch 1613/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0381\n",
      "Epoch 1614/10000\n",
      "249/249 [==============================] - 2s 8ms/step - loss: 0.0041 - val_loss: 0.0388\n",
      "Epoch 1615/10000\n",
      "249/249 [==============================] - 2s 8ms/step - loss: 0.0042 - val_loss: 0.0383\n",
      "Epoch 1616/10000\n",
      "249/249 [==============================] - 2s 8ms/step - loss: 0.0041 - val_loss: 0.0378\n",
      "Epoch 1617/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0042 - val_loss: 0.0372\n",
      "Epoch 1618/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0042 - val_loss: 0.0380\n",
      "Epoch 1619/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0042 - val_loss: 0.0381\n",
      "Epoch 1620/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0041 - val_loss: 0.0380\n",
      "Epoch 1621/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0042 - val_loss: 0.0385\n",
      "Epoch 1622/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0043 - val_loss: 0.0384\n",
      "Epoch 1623/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0380\n",
      "Epoch 1624/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0042 - val_loss: 0.0378\n",
      "Epoch 1625/10000\n",
      "249/249 [==============================] - 2s 9ms/step - loss: 0.0041 - val_loss: 0.0391\n",
      "Epoch 1626/10000\n",
      "249/249 [==============================] - 2s 9ms/step - loss: 0.0041 - val_loss: 0.0376\n",
      "Epoch 1627/10000\n",
      "249/249 [==============================] - 2s 10ms/step - loss: 0.0042 - val_loss: 0.0391\n",
      "Epoch 1628/10000\n",
      "249/249 [==============================] - 3s 10ms/step - loss: 0.0041 - val_loss: 0.0387\n",
      "Epoch 1629/10000\n",
      "249/249 [==============================] - 2s 9ms/step - loss: 0.0041 - val_loss: 0.0381\n",
      "Epoch 1630/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0041 - val_loss: 0.0388\n",
      "Epoch 1631/10000\n",
      "249/249 [==============================] - 2s 10ms/step - loss: 0.0042 - val_loss: 0.0391\n",
      "Epoch 1632/10000\n",
      "249/249 [==============================] - 3s 12ms/step - loss: 0.0041 - val_loss: 0.0389\n",
      "Epoch 1633/10000\n",
      "249/249 [==============================] - 2s 8ms/step - loss: 0.0041 - val_loss: 0.0379\n",
      "Epoch 1634/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0389\n",
      "Epoch 1635/10000\n",
      "249/249 [==============================] - 2s 8ms/step - loss: 0.0041 - val_loss: 0.0379\n",
      "Epoch 1636/10000\n",
      "249/249 [==============================] - 2s 9ms/step - loss: 0.0042 - val_loss: 0.0382\n",
      "Epoch 1637/10000\n",
      "249/249 [==============================] - 2s 9ms/step - loss: 0.0042 - val_loss: 0.0394\n",
      "Epoch 1638/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0041 - val_loss: 0.0371\n",
      "Epoch 1639/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0381\n",
      "Epoch 1640/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0042 - val_loss: 0.0379\n",
      "Epoch 1641/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0380\n",
      "Epoch 1642/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0394\n",
      "Epoch 1643/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0381\n",
      "Epoch 1644/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0374\n",
      "Epoch 1645/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0387\n",
      "Epoch 1646/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0381\n",
      "Epoch 1647/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0376\n",
      "Epoch 1648/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0384\n",
      "Epoch 1649/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0380\n",
      "Epoch 1650/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0390\n",
      "Epoch 1651/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0376\n",
      "Epoch 1652/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0377\n",
      "Epoch 1653/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0389\n",
      "Epoch 1654/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0384\n",
      "Epoch 1655/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0390\n",
      "Epoch 1656/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0377\n",
      "Epoch 1657/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0379\n",
      "Epoch 1658/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0385\n",
      "Epoch 1659/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0382\n",
      "Epoch 1660/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0381\n",
      "Epoch 1661/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0380\n",
      "Epoch 1662/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0376\n",
      "Epoch 1663/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0374\n",
      "Epoch 1664/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0394\n",
      "Epoch 1665/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0385\n",
      "Epoch 1666/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0040 - val_loss: 0.0381\n",
      "Epoch 1667/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0041 - val_loss: 0.0388\n",
      "Epoch 1668/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0384\n",
      "Epoch 1669/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0381\n",
      "Epoch 1670/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0387\n",
      "Epoch 1671/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0377\n",
      "Epoch 1672/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0393\n",
      "Epoch 1673/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0389\n",
      "Epoch 1674/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0375\n",
      "Epoch 1675/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0394\n",
      "Epoch 1676/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0391\n",
      "Epoch 1677/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0040 - val_loss: 0.0388\n",
      "Epoch 1678/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0382\n",
      "Epoch 1679/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0378\n",
      "Epoch 1680/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0388\n",
      "Epoch 1681/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0378\n",
      "Epoch 1682/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0372\n",
      "Epoch 1683/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0389\n",
      "Epoch 1684/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0375\n",
      "Epoch 1685/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0385\n",
      "Epoch 1686/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0381\n",
      "Epoch 1687/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0386\n",
      "Epoch 1688/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0042 - val_loss: 0.0384\n",
      "Epoch 1689/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0389\n",
      "Epoch 1690/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0374\n",
      "Epoch 1691/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0380\n",
      "Epoch 1692/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0375\n",
      "Epoch 1693/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0382\n",
      "Epoch 1694/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0388\n",
      "Epoch 1695/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0374\n",
      "Epoch 1696/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0371\n",
      "Epoch 1697/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0379\n",
      "Epoch 1698/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0388\n",
      "Epoch 1699/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0384\n",
      "Epoch 1700/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0041 - val_loss: 0.0371\n",
      "Epoch 1701/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0385\n",
      "Epoch 1702/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0382\n",
      "Epoch 1703/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0374\n",
      "Epoch 1704/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0382\n",
      "Epoch 1705/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0381\n",
      "Epoch 1706/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0373\n",
      "Epoch 1707/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0378\n",
      "Epoch 1708/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0372\n",
      "Epoch 1709/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0374\n",
      "Epoch 1710/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0377\n",
      "Epoch 1711/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0041 - val_loss: 0.0380\n",
      "Epoch 1712/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0378\n",
      "Epoch 1713/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0373\n",
      "Epoch 1714/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0378\n",
      "Epoch 1715/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0388\n",
      "Epoch 1716/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0391\n",
      "Epoch 1717/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0380\n",
      "Epoch 1718/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0385\n",
      "Epoch 1719/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0371\n",
      "Epoch 1720/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0393\n",
      "Epoch 1721/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0378\n",
      "Epoch 1722/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0041 - val_loss: 0.0372\n",
      "Epoch 1723/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0378\n",
      "Epoch 1724/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0384\n",
      "Epoch 1725/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0394\n",
      "Epoch 1726/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0385\n",
      "Epoch 1727/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0378\n",
      "Epoch 1728/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0377\n",
      "Epoch 1729/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0393\n",
      "Epoch 1730/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0386\n",
      "Epoch 1731/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0390\n",
      "Epoch 1732/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0388\n",
      "Epoch 1733/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0040 - val_loss: 0.0385\n",
      "Epoch 1734/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0384\n",
      "Epoch 1735/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0376\n",
      "Epoch 1736/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0400\n",
      "Epoch 1737/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0375\n",
      "Epoch 1738/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0377\n",
      "Epoch 1739/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0384\n",
      "Epoch 1740/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0388\n",
      "Epoch 1741/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0386\n",
      "Epoch 1742/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0380\n",
      "Epoch 1743/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0382\n",
      "Epoch 1744/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0385\n",
      "Epoch 1745/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0391\n",
      "Epoch 1746/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0375\n",
      "Epoch 1747/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0384\n",
      "Epoch 1748/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0385\n",
      "Epoch 1749/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0380\n",
      "Epoch 1750/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0385\n",
      "Epoch 1751/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0386\n",
      "Epoch 1752/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0388\n",
      "Epoch 1753/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0380\n",
      "Epoch 1754/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0040 - val_loss: 0.0384\n",
      "Epoch 1755/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0040 - val_loss: 0.0380\n",
      "Epoch 1756/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0388\n",
      "Epoch 1757/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0390\n",
      "Epoch 1758/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0376\n",
      "Epoch 1759/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0389\n",
      "Epoch 1760/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0384\n",
      "Epoch 1761/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0379\n",
      "Epoch 1762/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0374\n",
      "Epoch 1763/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0377\n",
      "Epoch 1764/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0379\n",
      "Epoch 1765/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0385\n",
      "Epoch 1766/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0041 - val_loss: 0.0380\n",
      "Epoch 1767/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0376\n",
      "Epoch 1768/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0379\n",
      "Epoch 1769/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0385\n",
      "Epoch 1770/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0041 - val_loss: 0.0384\n",
      "Epoch 1771/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0368\n",
      "Epoch 1772/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0379\n",
      "Epoch 1773/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0388\n",
      "Epoch 1774/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0393\n",
      "Epoch 1775/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0369\n",
      "Epoch 1776/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0375\n",
      "Epoch 1777/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0384\n",
      "Epoch 1778/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0383\n",
      "Epoch 1779/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0379\n",
      "Epoch 1780/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0381\n",
      "Epoch 1781/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0377\n",
      "Epoch 1782/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0372\n",
      "Epoch 1783/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0370\n",
      "Epoch 1784/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0381\n",
      "Epoch 1785/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0373\n",
      "Epoch 1786/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0377\n",
      "Epoch 1787/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0383\n",
      "Epoch 1788/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0041 - val_loss: 0.0381\n",
      "Epoch 1789/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0040 - val_loss: 0.0373\n",
      "Epoch 1790/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0040 - val_loss: 0.0368\n",
      "Epoch 1791/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0040 - val_loss: 0.0383\n",
      "Epoch 1792/10000\n",
      "249/249 [==============================] - 2s 8ms/step - loss: 0.0040 - val_loss: 0.0376\n",
      "Epoch 1793/10000\n",
      "249/249 [==============================] - 2s 8ms/step - loss: 0.0041 - val_loss: 0.0391\n",
      "Epoch 1794/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0041 - val_loss: 0.0386\n",
      "Epoch 1795/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0040 - val_loss: 0.0395\n",
      "Epoch 1796/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0041 - val_loss: 0.0386\n",
      "Epoch 1797/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0041 - val_loss: 0.0386\n",
      "Epoch 1798/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0040 - val_loss: 0.0388\n",
      "Epoch 1799/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0041 - val_loss: 0.0388\n",
      "Epoch 1800/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0041 - val_loss: 0.0388\n",
      "Epoch 1801/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0380\n",
      "Epoch 1802/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0039 - val_loss: 0.0386\n",
      "Epoch 1803/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0040 - val_loss: 0.0380\n",
      "Epoch 1804/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0394\n",
      "Epoch 1805/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0384\n",
      "Epoch 1806/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0398\n",
      "Epoch 1807/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0041 - val_loss: 0.0382\n",
      "Epoch 1808/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0040 - val_loss: 0.0384\n",
      "Epoch 1809/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0041 - val_loss: 0.0373\n",
      "Epoch 1810/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0040 - val_loss: 0.0376\n",
      "Epoch 1811/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0378\n",
      "Epoch 1812/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0388\n",
      "Epoch 1813/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0376\n",
      "Epoch 1814/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0380\n",
      "Epoch 1815/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0380\n",
      "Epoch 1816/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0384\n",
      "Epoch 1817/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0375\n",
      "Epoch 1818/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0041 - val_loss: 0.0383\n",
      "Epoch 1819/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0041 - val_loss: 0.0393\n",
      "Epoch 1820/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0040 - val_loss: 0.0383\n",
      "Epoch 1821/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0041 - val_loss: 0.0382\n",
      "Epoch 1822/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0040 - val_loss: 0.0390\n",
      "Epoch 1823/10000\n",
      "249/249 [==============================] - 2s 7ms/step - loss: 0.0040 - val_loss: 0.0393\n",
      "Epoch 1824/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0382\n",
      "Epoch 1825/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0382\n",
      "Epoch 1826/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0375\n",
      "Epoch 1827/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0385\n",
      "Epoch 1828/10000\n",
      "249/249 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0380\n",
      "Epoch 1829/10000\n",
      "249/249 [==============================] - 2s 6ms/step - loss: 0.0040 - val_loss: 0.0377\n",
      "Epoch 1830/10000\n",
      "239/249 [===========================>..] - ETA: 0s - loss: 0.0041"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def build_and_compile_model(norm):\n",
    "  model = keras.Sequential([\n",
    "      norm,\n",
    "      layers.Dense(440, activation='relu'),\n",
    "      layers.Dense(440, activation='relu'),\n",
    "      layers.Dense(440, activation='relu'),\n",
    "      layers.Dense(1, activation=\"linear\")\n",
    "  ])\n",
    "\n",
    "  model.compile(loss='mean_absolute_error',\n",
    "                optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "  return model\n",
    "\n",
    "\n",
    "\n",
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "\n",
    "normalizer.adapt(np.array(np.array(XTrain_)))\n",
    "print(normalizer.mean.numpy())\n",
    "\n",
    "\n",
    "\n",
    "dnn_model = build_and_compile_model(normalizer)\n",
    "\n",
    "\n",
    "\n",
    "history = dnn_model.fit(\n",
    "    np.array(XTrain_),\n",
    "    np.array(YTrain),\n",
    "    validation_split=0.2,\n",
    "    verbose=1, epochs=10000, batch_size=100)\n",
    "\n",
    "\n",
    "dnn_model.predict(np.array(XTest_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "430/430 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = dnn_model.predict(np.array(XTest_))\n",
    "\n",
    "\n",
    "df = pd.DataFrame(prediction, columns=['p0q0'], index = np.arange(1, prediction.size+1))\n",
    "df.to_csv(\"prediction_RN5_good.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25436968],\n",
       "       [0.24707955],\n",
       "       [0.25191575],\n",
       "       ...,\n",
       "       [0.13367376],\n",
       "       [0.18309915],\n",
       "       [0.14375857]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
