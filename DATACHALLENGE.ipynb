{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATACHALLENGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour ce datachallenge, nous aurons besoin des modules Python ci-dessous, il vous faut donc évidemment exécuter cette première cellule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les différentes méthodes dont nous aurons besoins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Pour importer les fichiers csv\n",
    "pd.read_csv\n",
    "\n",
    "### Pour créer nos echantillons de train et de test\n",
    "from sklearn import model_selection.train_test_split\n",
    "\n",
    "model_selection.train_test_split\n",
    "\n",
    "### Pour calculer une regression linéaire\n",
    "from sklearn import linear_model\n",
    "\n",
    "linear_model.LogisticRegression\n",
    "\n",
    "### Pour faire une PCA\n",
    "from sklearn import decomposition\n",
    "\n",
    "decomposition.PCA\n",
    "\n",
    "### Classificatuer gaussien\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "### Classificateur k-voisins\n",
    "from sklearn import neighbors\n",
    "\n",
    "neighbors.KNeighborsClassifier\n",
    "\n",
    "### Regression logistique\n",
    "from sklearn import linear_model\n",
    "\n",
    "linear_model.LogisticRegression\n",
    "\n",
    "### Regression logistique lasso\n",
    "from sklearn import linear_model\n",
    "\n",
    "linear_model.LogisticRegressionCV\n",
    "\n",
    "### Decision Tree\n",
    "sklearn.tree.DecisionTreeClassifier\n",
    "\n",
    "### Bagged Tree\n",
    "sklearn.tree.DecisionTreeRegressor\n",
    "\n",
    "### Trouver la meilleur valeur d'un paramètre\n",
    "form sklearn import model_selection\n",
    "\n",
    "model_selection.GridSearchCV\n",
    "\n",
    "### Créer une répartition d'échantillon de test aléatoire\n",
    "from sklearn import model_selection\n",
    "\n",
    "model_selection.KFold\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons importer toutes les données qui vont nous être utiles, même celles qui ne seront pas utiles avant la fin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "XTrain_Path = \"Xtrain_hgcGIrA.csv\"\n",
    "YTrain_Path = \"Ytrain_yL5OjS4.csv\"\n",
    "XTest_Path = \"Xtest.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "XTrain  =    pd.read_csv(XTrain_Path).to_numpy()\n",
    "YTrain  =    pd.read_csv(YTrain_Path).to_numpy()\n",
    "XTest  =    pd.read_csv(XTest_Path).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['2019-01-07', 1, 0, ..., 0.201, 0.138, 0.091],\n",
       "       ['2019-01-08', 1, 0, ..., 0.204, 0.152, 0.106],\n",
       "       ['2019-01-10', 1, 0, ..., 0.213, 0.153, 0.111],\n",
       "       ...,\n",
       "       ['2019-05-15', 9, 0, ..., 0.099, 0.129, nan],\n",
       "       ['2019-03-21', 9, 0, ..., 0.074, 0.101, nan],\n",
       "       ['2019-01-30', 9, 0, ..., 0.289, 0.354, nan]], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Découpage train / test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En apprentissage statistique, classiquement un prédicteur est ajusté sur une partie seulement des données et l'erreur de ce dernier est ensuite évaluée sur une autre partie des données disponibles. Ceci permet de ne pas utiliser les mêmes données pour ajuster et évaluer la qualité d'un prédicteur. Cette problématique est l'objet du prochain chapitre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> En utilisant la fonction [`train_test_split`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split) de la librairie [`sklearn.model_selection`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection), sélectionner aléatoirement 60% des observations pour l'échantillon d'apprentissage et garder le reste pour l'échantillon de test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "ntot = XTrain.size\n",
    "\n",
    "XTrain_train,XTrain_test,YTrain_train, YTrain_test = model_selection.train_test_split(XTrain, YTrain, test_size=0.4, train_size=0.6, random_state=0, shuffle=True, stratify=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
